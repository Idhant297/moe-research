{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import OlmoeForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.special import kl_div\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference for olmoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa4651f20554e1186f6d832cd1b6bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "OlmoeForCausalLM(\n",
       "  (model): OlmoeModel(\n",
       "    (embed_tokens): Embedding(50304, 2048, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x OlmoeDecoderLayer(\n",
       "        (self_attn): OlmoeSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (q_norm): OlmoeRMSNorm((2048,), eps=1e-05)\n",
       "          (k_norm): OlmoeRMSNorm((2048,), eps=1e-05)\n",
       "        )\n",
       "        (mlp): OlmoeSparseMoeBlock(\n",
       "          (gate): Linear(in_features=2048, out_features=64, bias=False)\n",
       "          (experts): ModuleList(\n",
       "            (0-63): 64 x OlmoeMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (down_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): OlmoeRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): OlmoeRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): OlmoeRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): OlmoeRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model = OlmoeForCausalLM.from_pretrained(\"allenai/OLMoE-1B-7B-0924\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMoE-1B-7B-0924\")\n",
    "\n",
    "# Set the model to eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to get the router logits and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_expert_routing(input_text, model, tokenizer):\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Print the tokenized input\n",
    "    print(\"Tokenized input:\")\n",
    "    for token_id in inputs.input_ids[0]:\n",
    "        token = tokenizer.decode([token_id])\n",
    "        print(f\"Token: '{token}', ID: {token_id.item()}\")\n",
    "\n",
    "    print(f\"\\nInput shape: {inputs.input_ids.shape}\")\n",
    "\n",
    "    # Forward pass with output_router_logits=True\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_router_logits=True)\n",
    "\n",
    "    # Get the router logits from the last layer\n",
    "    last_layer_router_logits = outputs.router_logits[-1]\n",
    "\n",
    "    # Initialize a dictionary to store the analysis results\n",
    "    analysis_results = {\n",
    "        \"input_text\": input_text,\n",
    "        \"tokens\": []\n",
    "    }\n",
    "\n",
    "    # Print router logits and probabilities for each token\n",
    "    print(\"\\nRouter logits and probabilities for each token:\")\n",
    "    for token_idx, token_id in enumerate(inputs.input_ids[0]):\n",
    "        token = tokenizer.decode([token_id])\n",
    "        logits = last_layer_router_logits[token_idx]\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        print(f\"Token: '{token}' (ID: {token_id.item()})\")\n",
    "        for expert_idx, (logit, prob) in enumerate(zip(logits, probabilities)):\n",
    "            print(f\"  expert {expert_idx}: logit = {logit.item():.4f}, post-softmax = {prob.item():.4f}\")\n",
    "        print()\n",
    "        \n",
    "        token_data = {\n",
    "            \"token\": token,\n",
    "            \"id\": token_id.item(),\n",
    "            \"router_probability\": probabilities.tolist()\n",
    "        }\n",
    "        analysis_results[\"tokens\"].append(token_data)\n",
    "\n",
    "    # Print the top-k experts for each token\n",
    "    k = 8\n",
    "    print(f\"\\nTop {k} experts for each token:\")\n",
    "    for token_idx, token_id in enumerate(inputs.input_ids[0]):\n",
    "        token = tokenizer.decode([token_id])\n",
    "        probabilities = F.softmax(last_layer_router_logits[token_idx], dim=-1)\n",
    "        top_k_probs, top_k_indices = torch.topk(probabilities, k)\n",
    "        \n",
    "        print(f\"Token: '{token}' (ID: {token_id.item()})\")\n",
    "        for i, (prob, idx) in enumerate(zip(top_k_probs, top_k_indices)):\n",
    "            print(f\"  {i+1}. expert {idx.item()}: probability = {prob.item():.4f}\")\n",
    "        print()\n",
    "\n",
    "    # Save the analysis results as a JSON file with a unique name\n",
    "    base_filename = \"expert_routing_analysis\"\n",
    "    counter = 1\n",
    "    filename = f\"{base_filename}_{counter}.json\"\n",
    "    while os.path.exists(filename):\n",
    "        counter += 1\n",
    "        filename = f\"{base_filename}_{counter}.json\"\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(analysis_results, f, indent=2)\n",
    "\n",
    "    print(f\"Analysis results saved to {filename}\")\n",
    "\n",
    "    return last_layer_router_logits, analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input:\n",
      "Token: 'What', ID: 1276\n",
      "Token: ''s', ID: 434\n",
      "Token: ' the', ID: 253\n",
      "Token: ' musical', ID: 12256\n",
      "Token: ' pitch', ID: 11288\n",
      "Token: ' of', ID: 273\n",
      "Token: ' that', ID: 326\n",
      "Token: ' note', ID: 3877\n",
      "Token: '?', ID: 32\n",
      "\n",
      "Input shape: torch.Size([1, 9])\n",
      "\n",
      "Router logits and probabilities for each token:\n",
      "Token: 'What' (ID: 1276)\n",
      "  expert 0: logit = -0.8721, post-softmax = 0.0151\n",
      "  expert 1: logit = -1.5355, post-softmax = 0.0078\n",
      "  expert 2: logit = -1.5983, post-softmax = 0.0073\n",
      "  expert 3: logit = -2.1905, post-softmax = 0.0040\n",
      "  expert 4: logit = -0.3444, post-softmax = 0.0256\n",
      "  expert 5: logit = -0.5635, post-softmax = 0.0206\n",
      "  expert 6: logit = -2.0390, post-softmax = 0.0047\n",
      "  expert 7: logit = -2.2326, post-softmax = 0.0039\n",
      "  expert 8: logit = -1.6298, post-softmax = 0.0071\n",
      "  expert 9: logit = -2.6304, post-softmax = 0.0026\n",
      "  expert 10: logit = -1.9941, post-softmax = 0.0049\n",
      "  expert 11: logit = -0.3353, post-softmax = 0.0258\n",
      "  expert 12: logit = 2.0358, post-softmax = 0.2768\n",
      "  expert 13: logit = -1.8599, post-softmax = 0.0056\n",
      "  expert 14: logit = -0.7361, post-softmax = 0.0173\n",
      "  expert 15: logit = -1.4064, post-softmax = 0.0089\n",
      "  expert 16: logit = -1.3277, post-softmax = 0.0096\n",
      "  expert 17: logit = -1.5145, post-softmax = 0.0079\n",
      "  expert 18: logit = -0.7043, post-softmax = 0.0179\n",
      "  expert 19: logit = -1.5794, post-softmax = 0.0074\n",
      "  expert 20: logit = -0.7162, post-softmax = 0.0177\n",
      "  expert 21: logit = -1.4668, post-softmax = 0.0083\n",
      "  expert 22: logit = -0.4997, post-softmax = 0.0219\n",
      "  expert 23: logit = -1.3274, post-softmax = 0.0096\n",
      "  expert 24: logit = -0.8594, post-softmax = 0.0153\n",
      "  expert 25: logit = -1.4698, post-softmax = 0.0083\n",
      "  expert 26: logit = -2.6668, post-softmax = 0.0025\n",
      "  expert 27: logit = -1.9644, post-softmax = 0.0051\n",
      "  expert 28: logit = 0.3869, post-softmax = 0.0532\n",
      "  expert 29: logit = -2.7114, post-softmax = 0.0024\n",
      "  expert 30: logit = -1.8337, post-softmax = 0.0058\n",
      "  expert 31: logit = -1.5953, post-softmax = 0.0073\n",
      "  expert 32: logit = -1.5674, post-softmax = 0.0075\n",
      "  expert 33: logit = -1.9995, post-softmax = 0.0049\n",
      "  expert 34: logit = -1.6220, post-softmax = 0.0071\n",
      "  expert 35: logit = -1.5673, post-softmax = 0.0075\n",
      "  expert 36: logit = -1.6929, post-softmax = 0.0067\n",
      "  expert 37: logit = -0.4685, post-softmax = 0.0226\n",
      "  expert 38: logit = -1.6396, post-softmax = 0.0070\n",
      "  expert 39: logit = -1.4804, post-softmax = 0.0082\n",
      "  expert 40: logit = -0.6470, post-softmax = 0.0189\n",
      "  expert 41: logit = -1.2586, post-softmax = 0.0103\n",
      "  expert 42: logit = -1.5840, post-softmax = 0.0074\n",
      "  expert 43: logit = -1.8202, post-softmax = 0.0059\n",
      "  expert 44: logit = -1.4737, post-softmax = 0.0083\n",
      "  expert 45: logit = -2.9743, post-softmax = 0.0018\n",
      "  expert 46: logit = -2.1089, post-softmax = 0.0044\n",
      "  expert 47: logit = -2.2534, post-softmax = 0.0038\n",
      "  expert 48: logit = -2.9598, post-softmax = 0.0019\n",
      "  expert 49: logit = -2.4677, post-softmax = 0.0031\n",
      "  expert 50: logit = -0.3496, post-softmax = 0.0255\n",
      "  expert 51: logit = -1.6853, post-softmax = 0.0067\n",
      "  expert 52: logit = -0.3900, post-softmax = 0.0245\n",
      "  expert 53: logit = -2.0528, post-softmax = 0.0046\n",
      "  expert 54: logit = -1.9098, post-softmax = 0.0054\n",
      "  expert 55: logit = -1.0333, post-softmax = 0.0129\n",
      "  expert 56: logit = -1.2984, post-softmax = 0.0099\n",
      "  expert 57: logit = -2.1483, post-softmax = 0.0042\n",
      "  expert 58: logit = -1.9842, post-softmax = 0.0050\n",
      "  expert 59: logit = -1.3951, post-softmax = 0.0090\n",
      "  expert 60: logit = -2.3239, post-softmax = 0.0035\n",
      "  expert 61: logit = -2.1936, post-softmax = 0.0040\n",
      "  expert 62: logit = -1.5325, post-softmax = 0.0078\n",
      "  expert 63: logit = 1.0311, post-softmax = 0.1014\n",
      "\n",
      "Token: ''s' (ID: 434)\n",
      "  expert 0: logit = -1.2564, post-softmax = 0.0133\n",
      "  expert 1: logit = -1.9465, post-softmax = 0.0067\n",
      "  expert 2: logit = -2.7148, post-softmax = 0.0031\n",
      "  expert 3: logit = -1.6385, post-softmax = 0.0091\n",
      "  expert 4: logit = -1.4649, post-softmax = 0.0108\n",
      "  expert 5: logit = -2.7556, post-softmax = 0.0030\n",
      "  expert 6: logit = -1.6506, post-softmax = 0.0090\n",
      "  expert 7: logit = -0.7930, post-softmax = 0.0212\n",
      "  expert 8: logit = -1.0766, post-softmax = 0.0159\n",
      "  expert 9: logit = -0.4146, post-softmax = 0.0309\n",
      "  expert 10: logit = -0.6714, post-softmax = 0.0239\n",
      "  expert 11: logit = -2.4232, post-softmax = 0.0041\n",
      "  expert 12: logit = -0.7093, post-softmax = 0.0230\n",
      "  expert 13: logit = -0.5628, post-softmax = 0.0267\n",
      "  expert 14: logit = -1.0877, post-softmax = 0.0158\n",
      "  expert 15: logit = 0.5005, post-softmax = 0.0772\n",
      "  expert 16: logit = -1.3873, post-softmax = 0.0117\n",
      "  expert 17: logit = -1.3506, post-softmax = 0.0121\n",
      "  expert 18: logit = -0.4742, post-softmax = 0.0291\n",
      "  expert 19: logit = -2.5967, post-softmax = 0.0035\n",
      "  expert 20: logit = -2.5324, post-softmax = 0.0037\n",
      "  expert 21: logit = -2.0554, post-softmax = 0.0060\n",
      "  expert 22: logit = -1.6291, post-softmax = 0.0092\n",
      "  expert 23: logit = -2.5852, post-softmax = 0.0035\n",
      "  expert 24: logit = 0.1765, post-softmax = 0.0558\n",
      "  expert 25: logit = -1.2351, post-softmax = 0.0136\n",
      "  expert 26: logit = -1.3014, post-softmax = 0.0127\n",
      "  expert 27: logit = -1.1049, post-softmax = 0.0155\n",
      "  expert 28: logit = -1.2010, post-softmax = 0.0141\n",
      "  expert 29: logit = -1.1902, post-softmax = 0.0142\n",
      "  expert 30: logit = -0.8612, post-softmax = 0.0198\n",
      "  expert 31: logit = -1.9732, post-softmax = 0.0065\n",
      "  expert 32: logit = -1.4157, post-softmax = 0.0114\n",
      "  expert 33: logit = -2.0283, post-softmax = 0.0062\n",
      "  expert 34: logit = -1.2391, post-softmax = 0.0136\n",
      "  expert 35: logit = -2.1614, post-softmax = 0.0054\n",
      "  expert 36: logit = -2.5256, post-softmax = 0.0037\n",
      "  expert 37: logit = -2.3765, post-softmax = 0.0043\n",
      "  expert 38: logit = -0.8911, post-softmax = 0.0192\n",
      "  expert 39: logit = -0.9931, post-softmax = 0.0173\n",
      "  expert 40: logit = -2.5411, post-softmax = 0.0037\n",
      "  expert 41: logit = -2.3329, post-softmax = 0.0045\n",
      "  expert 42: logit = -2.0236, post-softmax = 0.0062\n",
      "  expert 43: logit = -2.5645, post-softmax = 0.0036\n",
      "  expert 44: logit = -1.9815, post-softmax = 0.0065\n",
      "  expert 45: logit = -0.9112, post-softmax = 0.0188\n",
      "  expert 46: logit = -1.1014, post-softmax = 0.0156\n",
      "  expert 47: logit = -2.7115, post-softmax = 0.0031\n",
      "  expert 48: logit = -1.2338, post-softmax = 0.0136\n",
      "  expert 49: logit = -0.9422, post-softmax = 0.0182\n",
      "  expert 50: logit = -0.3707, post-softmax = 0.0323\n",
      "  expert 51: logit = -1.0911, post-softmax = 0.0157\n",
      "  expert 52: logit = -0.0655, post-softmax = 0.0438\n",
      "  expert 53: logit = -2.1985, post-softmax = 0.0052\n",
      "  expert 54: logit = -2.5488, post-softmax = 0.0037\n",
      "  expert 55: logit = -2.5603, post-softmax = 0.0036\n",
      "  expert 56: logit = -1.6291, post-softmax = 0.0092\n",
      "  expert 57: logit = -2.6483, post-softmax = 0.0033\n",
      "  expert 58: logit = -2.1630, post-softmax = 0.0054\n",
      "  expert 59: logit = -0.7765, post-softmax = 0.0215\n",
      "  expert 60: logit = -1.9956, post-softmax = 0.0064\n",
      "  expert 61: logit = -1.1810, post-softmax = 0.0144\n",
      "  expert 62: logit = 0.6423, post-softmax = 0.0889\n",
      "  expert 63: logit = 0.0054, post-softmax = 0.0470\n",
      "\n",
      "Token: ' the' (ID: 253)\n",
      "  expert 0: logit = -2.2278, post-softmax = 0.0041\n",
      "  expert 1: logit = -1.4474, post-softmax = 0.0090\n",
      "  expert 2: logit = -3.4759, post-softmax = 0.0012\n",
      "  expert 3: logit = -1.0478, post-softmax = 0.0135\n",
      "  expert 4: logit = -2.0611, post-softmax = 0.0049\n",
      "  expert 5: logit = -2.6984, post-softmax = 0.0026\n",
      "  expert 6: logit = -1.7781, post-softmax = 0.0065\n",
      "  expert 7: logit = 0.3299, post-softmax = 0.0535\n",
      "  expert 8: logit = -0.6502, post-softmax = 0.0201\n",
      "  expert 9: logit = -0.8771, post-softmax = 0.0160\n",
      "  expert 10: logit = -3.7588, post-softmax = 0.0009\n",
      "  expert 11: logit = -2.7994, post-softmax = 0.0023\n",
      "  expert 12: logit = -0.6713, post-softmax = 0.0197\n",
      "  expert 13: logit = -3.6130, post-softmax = 0.0010\n",
      "  expert 14: logit = -0.2487, post-softmax = 0.0300\n",
      "  expert 15: logit = -3.0312, post-softmax = 0.0019\n",
      "  expert 16: logit = -1.7430, post-softmax = 0.0067\n",
      "  expert 17: logit = -1.0291, post-softmax = 0.0138\n",
      "  expert 18: logit = -0.2221, post-softmax = 0.0308\n",
      "  expert 19: logit = -1.7340, post-softmax = 0.0068\n",
      "  expert 20: logit = 0.2895, post-softmax = 0.0514\n",
      "  expert 21: logit = 0.3299, post-softmax = 0.0535\n",
      "  expert 22: logit = -1.0027, post-softmax = 0.0141\n",
      "  expert 23: logit = -3.3931, post-softmax = 0.0013\n",
      "  expert 24: logit = -0.2622, post-softmax = 0.0296\n",
      "  expert 25: logit = -0.1877, post-softmax = 0.0319\n",
      "  expert 26: logit = -0.4797, post-softmax = 0.0238\n",
      "  expert 27: logit = -0.2257, post-softmax = 0.0307\n",
      "  expert 28: logit = -2.0518, post-softmax = 0.0049\n",
      "  expert 29: logit = -1.0234, post-softmax = 0.0138\n",
      "  expert 30: logit = -0.5546, post-softmax = 0.0221\n",
      "  expert 31: logit = -2.0856, post-softmax = 0.0048\n",
      "  expert 32: logit = -0.4533, post-softmax = 0.0245\n",
      "  expert 33: logit = -0.8701, post-softmax = 0.0161\n",
      "  expert 34: logit = -0.7990, post-softmax = 0.0173\n",
      "  expert 35: logit = -1.9114, post-softmax = 0.0057\n",
      "  expert 36: logit = -2.4427, post-softmax = 0.0033\n",
      "  expert 37: logit = -0.3130, post-softmax = 0.0281\n",
      "  expert 38: logit = -0.4555, post-softmax = 0.0244\n",
      "  expert 39: logit = -0.5849, post-softmax = 0.0214\n",
      "  expert 40: logit = -2.8189, post-softmax = 0.0023\n",
      "  expert 41: logit = -2.3853, post-softmax = 0.0035\n",
      "  expert 42: logit = -0.9377, post-softmax = 0.0151\n",
      "  expert 43: logit = -3.1311, post-softmax = 0.0017\n",
      "  expert 44: logit = -1.5753, post-softmax = 0.0080\n",
      "  expert 45: logit = -1.8535, post-softmax = 0.0060\n",
      "  expert 46: logit = -4.3456, post-softmax = 0.0005\n",
      "  expert 47: logit = -2.2399, post-softmax = 0.0041\n",
      "  expert 48: logit = -1.4317, post-softmax = 0.0092\n",
      "  expert 49: logit = -0.4526, post-softmax = 0.0245\n",
      "  expert 50: logit = -0.1392, post-softmax = 0.0335\n",
      "  expert 51: logit = -0.0670, post-softmax = 0.0360\n",
      "  expert 52: logit = -0.2946, post-softmax = 0.0287\n",
      "  expert 53: logit = -1.0452, post-softmax = 0.0135\n",
      "  expert 54: logit = -3.9625, post-softmax = 0.0007\n",
      "  expert 55: logit = 0.7208, post-softmax = 0.0791\n",
      "  expert 56: logit = -2.5135, post-softmax = 0.0031\n",
      "  expert 57: logit = -2.1344, post-softmax = 0.0046\n",
      "  expert 58: logit = -2.4751, post-softmax = 0.0032\n",
      "  expert 59: logit = -0.2311, post-softmax = 0.0305\n",
      "  expert 60: logit = -2.4588, post-softmax = 0.0033\n",
      "  expert 61: logit = -2.1184, post-softmax = 0.0046\n",
      "  expert 62: logit = -3.1616, post-softmax = 0.0016\n",
      "  expert 63: logit = -0.9862, post-softmax = 0.0144\n",
      "\n",
      "Token: ' musical' (ID: 12256)\n",
      "  expert 0: logit = -1.1913, post-softmax = 0.0091\n",
      "  expert 1: logit = -1.9315, post-softmax = 0.0043\n",
      "  expert 2: logit = 0.0585, post-softmax = 0.0317\n",
      "  expert 3: logit = -1.8699, post-softmax = 0.0046\n",
      "  expert 4: logit = -1.6543, post-softmax = 0.0057\n",
      "  expert 5: logit = 1.3049, post-softmax = 0.1102\n",
      "  expert 6: logit = -2.0561, post-softmax = 0.0038\n",
      "  expert 7: logit = 0.0212, post-softmax = 0.0305\n",
      "  expert 8: logit = -0.7712, post-softmax = 0.0138\n",
      "  expert 9: logit = -1.1669, post-softmax = 0.0093\n",
      "  expert 10: logit = -3.1212, post-softmax = 0.0013\n",
      "  expert 11: logit = -1.7795, post-softmax = 0.0050\n",
      "  expert 12: logit = -0.5401, post-softmax = 0.0174\n",
      "  expert 13: logit = -2.8728, post-softmax = 0.0017\n",
      "  expert 14: logit = 0.3211, post-softmax = 0.0412\n",
      "  expert 15: logit = -2.3536, post-softmax = 0.0028\n",
      "  expert 16: logit = -1.9423, post-softmax = 0.0043\n",
      "  expert 17: logit = -0.8301, post-softmax = 0.0130\n",
      "  expert 18: logit = -0.8980, post-softmax = 0.0122\n",
      "  expert 19: logit = -0.8144, post-softmax = 0.0132\n",
      "  expert 20: logit = -0.0695, post-softmax = 0.0279\n",
      "  expert 21: logit = 0.1852, post-softmax = 0.0360\n",
      "  expert 22: logit = -0.4236, post-softmax = 0.0196\n",
      "  expert 23: logit = 0.3732, post-softmax = 0.0434\n",
      "  expert 24: logit = -0.3206, post-softmax = 0.0217\n",
      "  expert 25: logit = -0.4221, post-softmax = 0.0196\n",
      "  expert 26: logit = -0.2826, post-softmax = 0.0225\n",
      "  expert 27: logit = 0.4609, post-softmax = 0.0474\n",
      "  expert 28: logit = -0.9211, post-softmax = 0.0119\n",
      "  expert 29: logit = -1.3088, post-softmax = 0.0081\n",
      "  expert 30: logit = -0.8306, post-softmax = 0.0130\n",
      "  expert 31: logit = -1.6998, post-softmax = 0.0055\n",
      "  expert 32: logit = -3.0293, post-softmax = 0.0014\n",
      "  expert 33: logit = -1.4011, post-softmax = 0.0074\n",
      "  expert 34: logit = -1.1752, post-softmax = 0.0092\n",
      "  expert 35: logit = -2.0333, post-softmax = 0.0039\n",
      "  expert 36: logit = -1.2730, post-softmax = 0.0084\n",
      "  expert 37: logit = -1.9948, post-softmax = 0.0041\n",
      "  expert 38: logit = -0.8296, post-softmax = 0.0130\n",
      "  expert 39: logit = -0.8414, post-softmax = 0.0129\n",
      "  expert 40: logit = -0.1485, post-softmax = 0.0258\n",
      "  expert 41: logit = -1.2834, post-softmax = 0.0083\n",
      "  expert 42: logit = -0.5574, post-softmax = 0.0171\n",
      "  expert 43: logit = -2.1888, post-softmax = 0.0033\n",
      "  expert 44: logit = -1.3843, post-softmax = 0.0075\n",
      "  expert 45: logit = -2.2043, post-softmax = 0.0033\n",
      "  expert 46: logit = -3.7886, post-softmax = 0.0007\n",
      "  expert 47: logit = -0.1171, post-softmax = 0.0266\n",
      "  expert 48: logit = -1.8028, post-softmax = 0.0049\n",
      "  expert 49: logit = -0.7047, post-softmax = 0.0148\n",
      "  expert 50: logit = -1.7216, post-softmax = 0.0053\n",
      "  expert 51: logit = -0.8735, post-softmax = 0.0125\n",
      "  expert 52: logit = -0.5563, post-softmax = 0.0171\n",
      "  expert 53: logit = -1.9321, post-softmax = 0.0043\n",
      "  expert 54: logit = -0.6036, post-softmax = 0.0163\n",
      "  expert 55: logit = 0.4870, post-softmax = 0.0486\n",
      "  expert 56: logit = -2.8340, post-softmax = 0.0018\n",
      "  expert 57: logit = -2.1068, post-softmax = 0.0036\n",
      "  expert 58: logit = -1.6144, post-softmax = 0.0059\n",
      "  expert 59: logit = 1.0473, post-softmax = 0.0851\n",
      "  expert 60: logit = -2.4005, post-softmax = 0.0027\n",
      "  expert 61: logit = -2.4548, post-softmax = 0.0026\n",
      "  expert 62: logit = -2.8025, post-softmax = 0.0018\n",
      "  expert 63: logit = -1.3116, post-softmax = 0.0080\n",
      "\n",
      "Token: ' pitch' (ID: 11288)\n",
      "  expert 0: logit = -0.0804, post-softmax = 0.0296\n",
      "  expert 1: logit = -2.2040, post-softmax = 0.0035\n",
      "  expert 2: logit = 0.6996, post-softmax = 0.0645\n",
      "  expert 3: logit = -1.0594, post-softmax = 0.0111\n",
      "  expert 4: logit = -1.0677, post-softmax = 0.0110\n",
      "  expert 5: logit = -0.6382, post-softmax = 0.0169\n",
      "  expert 6: logit = -2.0830, post-softmax = 0.0040\n",
      "  expert 7: logit = -2.0058, post-softmax = 0.0043\n",
      "  expert 8: logit = -1.0409, post-softmax = 0.0113\n",
      "  expert 9: logit = -0.9488, post-softmax = 0.0124\n",
      "  expert 10: logit = -1.7017, post-softmax = 0.0058\n",
      "  expert 11: logit = -2.5249, post-softmax = 0.0026\n",
      "  expert 12: logit = -0.8704, post-softmax = 0.0134\n",
      "  expert 13: logit = -1.4476, post-softmax = 0.0075\n",
      "  expert 14: logit = -0.7937, post-softmax = 0.0145\n",
      "  expert 15: logit = -0.0469, post-softmax = 0.0306\n",
      "  expert 16: logit = -2.1162, post-softmax = 0.0039\n",
      "  expert 17: logit = 0.1549, post-softmax = 0.0374\n",
      "  expert 18: logit = -1.6168, post-softmax = 0.0064\n",
      "  expert 19: logit = -2.2331, post-softmax = 0.0034\n",
      "  expert 20: logit = -1.1791, post-softmax = 0.0099\n",
      "  expert 21: logit = -2.0080, post-softmax = 0.0043\n",
      "  expert 22: logit = -0.3900, post-softmax = 0.0217\n",
      "  expert 23: logit = 1.4031, post-softmax = 0.1304\n",
      "  expert 24: logit = -0.6994, post-softmax = 0.0159\n",
      "  expert 25: logit = -1.0343, post-softmax = 0.0114\n",
      "  expert 26: logit = 0.3258, post-softmax = 0.0444\n",
      "  expert 27: logit = -0.7303, post-softmax = 0.0154\n",
      "  expert 28: logit = -0.6799, post-softmax = 0.0162\n",
      "  expert 29: logit = -1.4577, post-softmax = 0.0075\n",
      "  expert 30: logit = -1.1448, post-softmax = 0.0102\n",
      "  expert 31: logit = -0.3346, post-softmax = 0.0229\n",
      "  expert 32: logit = -3.1698, post-softmax = 0.0013\n",
      "  expert 33: logit = -2.0477, post-softmax = 0.0041\n",
      "  expert 34: logit = 0.1511, post-softmax = 0.0373\n",
      "  expert 35: logit = -1.2459, post-softmax = 0.0092\n",
      "  expert 36: logit = -1.4433, post-softmax = 0.0076\n",
      "  expert 37: logit = -2.5874, post-softmax = 0.0024\n",
      "  expert 38: logit = -0.5727, post-softmax = 0.0181\n",
      "  expert 39: logit = -0.9463, post-softmax = 0.0124\n",
      "  expert 40: logit = -1.8678, post-softmax = 0.0050\n",
      "  expert 41: logit = -1.7805, post-softmax = 0.0054\n",
      "  expert 42: logit = -1.0106, post-softmax = 0.0117\n",
      "  expert 43: logit = -0.7371, post-softmax = 0.0153\n",
      "  expert 44: logit = -1.9921, post-softmax = 0.0044\n",
      "  expert 45: logit = -0.6162, post-softmax = 0.0173\n",
      "  expert 46: logit = -2.3505, post-softmax = 0.0031\n",
      "  expert 47: logit = -0.5384, post-softmax = 0.0187\n",
      "  expert 48: logit = -1.0382, post-softmax = 0.0113\n",
      "  expert 49: logit = -2.2174, post-softmax = 0.0035\n",
      "  expert 50: logit = -1.3228, post-softmax = 0.0085\n",
      "  expert 51: logit = -0.9306, post-softmax = 0.0126\n",
      "  expert 52: logit = -1.0503, post-softmax = 0.0112\n",
      "  expert 53: logit = -1.8140, post-softmax = 0.0052\n",
      "  expert 54: logit = 0.5823, post-softmax = 0.0574\n",
      "  expert 55: logit = -1.9217, post-softmax = 0.0047\n",
      "  expert 56: logit = -3.2290, post-softmax = 0.0013\n",
      "  expert 57: logit = -1.8035, post-softmax = 0.0053\n",
      "  expert 58: logit = -1.0508, post-softmax = 0.0112\n",
      "  expert 59: logit = 0.7272, post-softmax = 0.0663\n",
      "  expert 60: logit = -2.5312, post-softmax = 0.0026\n",
      "  expert 61: logit = -3.3209, post-softmax = 0.0012\n",
      "  expert 62: logit = -0.5771, post-softmax = 0.0180\n",
      "  expert 63: logit = -2.8053, post-softmax = 0.0019\n",
      "\n",
      "Token: ' of' (ID: 273)\n",
      "  expert 0: logit = -2.1054, post-softmax = 0.0071\n",
      "  expert 1: logit = -2.1939, post-softmax = 0.0065\n",
      "  expert 2: logit = -3.7687, post-softmax = 0.0014\n",
      "  expert 3: logit = -0.5580, post-softmax = 0.0335\n",
      "  expert 4: logit = -1.8858, post-softmax = 0.0089\n",
      "  expert 5: logit = -2.7673, post-softmax = 0.0037\n",
      "  expert 6: logit = -1.8569, post-softmax = 0.0091\n",
      "  expert 7: logit = -0.2603, post-softmax = 0.0452\n",
      "  expert 8: logit = -1.7383, post-softmax = 0.0103\n",
      "  expert 9: logit = -1.3778, post-softmax = 0.0148\n",
      "  expert 10: logit = -3.2084, post-softmax = 0.0024\n",
      "  expert 11: logit = -2.6348, post-softmax = 0.0042\n",
      "  expert 12: logit = -0.9993, post-softmax = 0.0216\n",
      "  expert 13: logit = -3.0986, post-softmax = 0.0026\n",
      "  expert 14: logit = -0.4565, post-softmax = 0.0371\n",
      "  expert 15: logit = -3.0832, post-softmax = 0.0027\n",
      "  expert 16: logit = -1.5613, post-softmax = 0.0123\n",
      "  expert 17: logit = -1.0289, post-softmax = 0.0209\n",
      "  expert 18: logit = -1.5161, post-softmax = 0.0129\n",
      "  expert 19: logit = -3.0012, post-softmax = 0.0029\n",
      "  expert 20: logit = -1.7055, post-softmax = 0.0106\n",
      "  expert 21: logit = -0.7478, post-softmax = 0.0277\n",
      "  expert 22: logit = -1.4153, post-softmax = 0.0142\n",
      "  expert 23: logit = -3.4382, post-softmax = 0.0019\n",
      "  expert 24: logit = -1.3004, post-softmax = 0.0160\n",
      "  expert 25: logit = -2.1612, post-softmax = 0.0067\n",
      "  expert 26: logit = -0.3062, post-softmax = 0.0431\n",
      "  expert 27: logit = -0.5798, post-softmax = 0.0328\n",
      "  expert 28: logit = -2.3774, post-softmax = 0.0054\n",
      "  expert 29: logit = -1.3180, post-softmax = 0.0157\n",
      "  expert 30: logit = -1.7264, post-softmax = 0.0104\n",
      "  expert 31: logit = -2.2036, post-softmax = 0.0065\n",
      "  expert 32: logit = -1.6382, post-softmax = 0.0114\n",
      "  expert 33: logit = -2.2722, post-softmax = 0.0060\n",
      "  expert 34: logit = -0.6926, post-softmax = 0.0293\n",
      "  expert 35: logit = -1.5552, post-softmax = 0.0124\n",
      "  expert 36: logit = -2.5363, post-softmax = 0.0046\n",
      "  expert 37: logit = -0.9140, post-softmax = 0.0235\n",
      "  expert 38: logit = -0.6884, post-softmax = 0.0294\n",
      "  expert 39: logit = -0.2269, post-softmax = 0.0467\n",
      "  expert 40: logit = -3.6372, post-softmax = 0.0015\n",
      "  expert 41: logit = -3.2216, post-softmax = 0.0023\n",
      "  expert 42: logit = -2.6766, post-softmax = 0.0040\n",
      "  expert 43: logit = -2.6633, post-softmax = 0.0041\n",
      "  expert 44: logit = -2.2288, post-softmax = 0.0063\n",
      "  expert 45: logit = -1.2235, post-softmax = 0.0172\n",
      "  expert 46: logit = -3.5405, post-softmax = 0.0017\n",
      "  expert 47: logit = -2.9471, post-softmax = 0.0031\n",
      "  expert 48: logit = -0.3503, post-softmax = 0.0413\n",
      "  expert 49: logit = -0.9634, post-softmax = 0.0224\n",
      "  expert 50: logit = -1.0932, post-softmax = 0.0196\n",
      "  expert 51: logit = -1.3937, post-softmax = 0.0145\n",
      "  expert 52: logit = -1.7771, post-softmax = 0.0099\n",
      "  expert 53: logit = -1.6723, post-softmax = 0.0110\n",
      "  expert 54: logit = -4.3325, post-softmax = 0.0008\n",
      "  expert 55: logit = -2.0420, post-softmax = 0.0076\n",
      "  expert 56: logit = 0.0905, post-softmax = 0.0641\n",
      "  expert 57: logit = -1.6188, post-softmax = 0.0116\n",
      "  expert 58: logit = -2.5340, post-softmax = 0.0046\n",
      "  expert 59: logit = -0.1858, post-softmax = 0.0486\n",
      "  expert 60: logit = -2.4152, post-softmax = 0.0052\n",
      "  expert 61: logit = 0.2368, post-softmax = 0.0742\n",
      "  expert 62: logit = -3.0104, post-softmax = 0.0029\n",
      "  expert 63: logit = -2.1660, post-softmax = 0.0067\n",
      "\n",
      "Token: ' that' (ID: 326)\n",
      "  expert 0: logit = -2.2940, post-softmax = 0.0046\n",
      "  expert 1: logit = -2.3027, post-softmax = 0.0046\n",
      "  expert 2: logit = -0.9993, post-softmax = 0.0169\n",
      "  expert 3: logit = -1.3597, post-softmax = 0.0118\n",
      "  expert 4: logit = -2.0536, post-softmax = 0.0059\n",
      "  expert 5: logit = -2.2500, post-softmax = 0.0049\n",
      "  expert 6: logit = -2.5385, post-softmax = 0.0036\n",
      "  expert 7: logit = 0.1312, post-softmax = 0.0525\n",
      "  expert 8: logit = -1.6711, post-softmax = 0.0087\n",
      "  expert 9: logit = -2.0319, post-softmax = 0.0060\n",
      "  expert 10: logit = -3.4377, post-softmax = 0.0015\n",
      "  expert 11: logit = -2.4134, post-softmax = 0.0041\n",
      "  expert 12: logit = -0.4673, post-softmax = 0.0288\n",
      "  expert 13: logit = -3.2739, post-softmax = 0.0017\n",
      "  expert 14: logit = -0.2245, post-softmax = 0.0368\n",
      "  expert 15: logit = -2.4576, post-softmax = 0.0039\n",
      "  expert 16: logit = -2.5472, post-softmax = 0.0036\n",
      "  expert 17: logit = -0.9376, post-softmax = 0.0180\n",
      "  expert 18: logit = -1.6922, post-softmax = 0.0085\n",
      "  expert 19: logit = -1.8007, post-softmax = 0.0076\n",
      "  expert 20: logit = 0.4791, post-softmax = 0.0743\n",
      "  expert 21: logit = 0.2120, post-softmax = 0.0569\n",
      "  expert 22: logit = -0.5842, post-softmax = 0.0257\n",
      "  expert 23: logit = -1.9852, post-softmax = 0.0063\n",
      "  expert 24: logit = -1.6374, post-softmax = 0.0090\n",
      "  expert 25: logit = -2.1001, post-softmax = 0.0056\n",
      "  expert 26: logit = -0.0169, post-softmax = 0.0453\n",
      "  expert 27: logit = -0.2040, post-softmax = 0.0375\n",
      "  expert 28: logit = -1.3034, post-softmax = 0.0125\n",
      "  expert 29: logit = -1.6349, post-softmax = 0.0090\n",
      "  expert 30: logit = -1.7898, post-softmax = 0.0077\n",
      "  expert 31: logit = -2.4584, post-softmax = 0.0039\n",
      "  expert 32: logit = -2.5188, post-softmax = 0.0037\n",
      "  expert 33: logit = -1.5008, post-softmax = 0.0103\n",
      "  expert 34: logit = -0.7568, post-softmax = 0.0216\n",
      "  expert 35: logit = -2.1857, post-softmax = 0.0052\n",
      "  expert 36: logit = -2.2516, post-softmax = 0.0048\n",
      "  expert 37: logit = -1.0046, post-softmax = 0.0169\n",
      "  expert 38: logit = -0.7869, post-softmax = 0.0210\n",
      "  expert 39: logit = -0.0266, post-softmax = 0.0448\n",
      "  expert 40: logit = -2.5040, post-softmax = 0.0038\n",
      "  expert 41: logit = -2.7643, post-softmax = 0.0029\n",
      "  expert 42: logit = -2.2747, post-softmax = 0.0047\n",
      "  expert 43: logit = -3.2228, post-softmax = 0.0018\n",
      "  expert 44: logit = -2.0758, post-softmax = 0.0058\n",
      "  expert 45: logit = -1.0286, post-softmax = 0.0165\n",
      "  expert 46: logit = -4.1187, post-softmax = 0.0007\n",
      "  expert 47: logit = 0.0384, post-softmax = 0.0478\n",
      "  expert 48: logit = -1.3662, post-softmax = 0.0117\n",
      "  expert 49: logit = -1.0853, post-softmax = 0.0155\n",
      "  expert 50: logit = -1.1855, post-softmax = 0.0141\n",
      "  expert 51: logit = -1.7601, post-softmax = 0.0079\n",
      "  expert 52: logit = -1.5992, post-softmax = 0.0093\n",
      "  expert 53: logit = -1.5996, post-softmax = 0.0093\n",
      "  expert 54: logit = -2.1395, post-softmax = 0.0054\n",
      "  expert 55: logit = 0.4182, post-softmax = 0.0699\n",
      "  expert 56: logit = -1.9912, post-softmax = 0.0063\n",
      "  expert 57: logit = -2.5138, post-softmax = 0.0037\n",
      "  expert 58: logit = -2.8114, post-softmax = 0.0028\n",
      "  expert 59: logit = 0.3366, post-softmax = 0.0645\n",
      "  expert 60: logit = -3.0082, post-softmax = 0.0023\n",
      "  expert 61: logit = -2.7090, post-softmax = 0.0031\n",
      "  expert 62: logit = -2.6967, post-softmax = 0.0031\n",
      "  expert 63: logit = -0.3985, post-softmax = 0.0309\n",
      "\n",
      "Token: ' note' (ID: 3877)\n",
      "  expert 0: logit = -1.3420, post-softmax = 0.0160\n",
      "  expert 1: logit = -2.5551, post-softmax = 0.0048\n",
      "  expert 2: logit = -0.1075, post-softmax = 0.0550\n",
      "  expert 3: logit = -1.1159, post-softmax = 0.0201\n",
      "  expert 4: logit = -0.9072, post-softmax = 0.0247\n",
      "  expert 5: logit = -1.9058, post-softmax = 0.0091\n",
      "  expert 6: logit = -1.9875, post-softmax = 0.0084\n",
      "  expert 7: logit = -2.8319, post-softmax = 0.0036\n",
      "  expert 8: logit = -1.7233, post-softmax = 0.0109\n",
      "  expert 9: logit = -1.3008, post-softmax = 0.0167\n",
      "  expert 10: logit = -1.4754, post-softmax = 0.0140\n",
      "  expert 11: logit = -1.5188, post-softmax = 0.0134\n",
      "  expert 12: logit = -0.9259, post-softmax = 0.0243\n",
      "  expert 13: logit = -1.2705, post-softmax = 0.0172\n",
      "  expert 14: logit = -2.1459, post-softmax = 0.0072\n",
      "  expert 15: logit = -0.1211, post-softmax = 0.0542\n",
      "  expert 16: logit = -1.4635, post-softmax = 0.0142\n",
      "  expert 17: logit = -0.5607, post-softmax = 0.0349\n",
      "  expert 18: logit = -1.3367, post-softmax = 0.0161\n",
      "  expert 19: logit = -2.0105, post-softmax = 0.0082\n",
      "  expert 20: logit = -2.5246, post-softmax = 0.0049\n",
      "  expert 21: logit = -3.5984, post-softmax = 0.0017\n",
      "  expert 22: logit = -1.2929, post-softmax = 0.0168\n",
      "  expert 23: logit = -0.0329, post-softmax = 0.0592\n",
      "  expert 24: logit = -1.3103, post-softmax = 0.0165\n",
      "  expert 25: logit = -2.9347, post-softmax = 0.0033\n",
      "  expert 26: logit = -1.4677, post-softmax = 0.0141\n",
      "  expert 27: logit = -1.9615, post-softmax = 0.0086\n",
      "  expert 28: logit = -1.2330, post-softmax = 0.0178\n",
      "  expert 29: logit = -1.7051, post-softmax = 0.0111\n",
      "  expert 30: logit = -1.7137, post-softmax = 0.0110\n",
      "  expert 31: logit = -1.8153, post-softmax = 0.0100\n",
      "  expert 32: logit = -2.0619, post-softmax = 0.0078\n",
      "  expert 33: logit = -1.4210, post-softmax = 0.0148\n",
      "  expert 34: logit = -0.8537, post-softmax = 0.0261\n",
      "  expert 35: logit = -1.6292, post-softmax = 0.0120\n",
      "  expert 36: logit = -1.5895, post-softmax = 0.0125\n",
      "  expert 37: logit = -1.9630, post-softmax = 0.0086\n",
      "  expert 38: logit = -1.6084, post-softmax = 0.0123\n",
      "  expert 39: logit = -1.5635, post-softmax = 0.0128\n",
      "  expert 40: logit = -2.1961, post-softmax = 0.0068\n",
      "  expert 41: logit = -2.2618, post-softmax = 0.0064\n",
      "  expert 42: logit = -2.7132, post-softmax = 0.0041\n",
      "  expert 43: logit = -1.7276, post-softmax = 0.0109\n",
      "  expert 44: logit = -2.6088, post-softmax = 0.0045\n",
      "  expert 45: logit = -0.9144, post-softmax = 0.0245\n",
      "  expert 46: logit = -1.8957, post-softmax = 0.0092\n",
      "  expert 47: logit = -0.0329, post-softmax = 0.0592\n",
      "  expert 48: logit = -1.4118, post-softmax = 0.0149\n",
      "  expert 49: logit = -2.4046, post-softmax = 0.0055\n",
      "  expert 50: logit = -0.9181, post-softmax = 0.0244\n",
      "  expert 51: logit = -2.1984, post-softmax = 0.0068\n",
      "  expert 52: logit = -1.7434, post-softmax = 0.0107\n",
      "  expert 53: logit = -1.6754, post-softmax = 0.0115\n",
      "  expert 54: logit = -0.6046, post-softmax = 0.0334\n",
      "  expert 55: logit = -3.6899, post-softmax = 0.0015\n",
      "  expert 56: logit = -3.5016, post-softmax = 0.0018\n",
      "  expert 57: logit = -1.9091, post-softmax = 0.0091\n",
      "  expert 58: logit = -2.0024, post-softmax = 0.0083\n",
      "  expert 59: logit = -0.3211, post-softmax = 0.0444\n",
      "  expert 60: logit = -2.3398, post-softmax = 0.0059\n",
      "  expert 61: logit = -4.2864, post-softmax = 0.0008\n",
      "  expert 62: logit = -0.4894, post-softmax = 0.0375\n",
      "  expert 63: logit = -3.0229, post-softmax = 0.0030\n",
      "\n",
      "Token: '?' (ID: 32)\n",
      "  expert 0: logit = -1.8654, post-softmax = 0.0069\n",
      "  expert 1: logit = -1.0243, post-softmax = 0.0160\n",
      "  expert 2: logit = -2.9173, post-softmax = 0.0024\n",
      "  expert 3: logit = 0.9604, post-softmax = 0.1167\n",
      "  expert 4: logit = -1.2235, post-softmax = 0.0131\n",
      "  expert 5: logit = -2.2261, post-softmax = 0.0048\n",
      "  expert 6: logit = -1.9567, post-softmax = 0.0063\n",
      "  expert 7: logit = -2.9815, post-softmax = 0.0023\n",
      "  expert 8: logit = -0.6874, post-softmax = 0.0225\n",
      "  expert 9: logit = -1.1770, post-softmax = 0.0138\n",
      "  expert 10: logit = -2.9203, post-softmax = 0.0024\n",
      "  expert 11: logit = -2.2059, post-softmax = 0.0049\n",
      "  expert 12: logit = 0.0869, post-softmax = 0.0487\n",
      "  expert 13: logit = -2.9636, post-softmax = 0.0023\n",
      "  expert 14: logit = -1.6358, post-softmax = 0.0087\n",
      "  expert 15: logit = -2.2315, post-softmax = 0.0048\n",
      "  expert 16: logit = -2.1501, post-softmax = 0.0052\n",
      "  expert 17: logit = 0.5788, post-softmax = 0.0797\n",
      "  expert 18: logit = -1.6576, post-softmax = 0.0085\n",
      "  expert 19: logit = -2.1666, post-softmax = 0.0051\n",
      "  expert 20: logit = -2.5873, post-softmax = 0.0034\n",
      "  expert 21: logit = -3.1064, post-softmax = 0.0020\n",
      "  expert 22: logit = -1.8904, post-softmax = 0.0067\n",
      "  expert 23: logit = -2.7491, post-softmax = 0.0029\n",
      "  expert 24: logit = -0.6288, post-softmax = 0.0238\n",
      "  expert 25: logit = -2.5601, post-softmax = 0.0035\n",
      "  expert 26: logit = -0.3660, post-softmax = 0.0310\n",
      "  expert 27: logit = -1.2640, post-softmax = 0.0126\n",
      "  expert 28: logit = -1.6943, post-softmax = 0.0082\n",
      "  expert 29: logit = -1.0682, post-softmax = 0.0154\n",
      "  expert 30: logit = -1.0234, post-softmax = 0.0161\n",
      "  expert 31: logit = -2.5354, post-softmax = 0.0035\n",
      "  expert 32: logit = -1.9299, post-softmax = 0.0065\n",
      "  expert 33: logit = -1.3847, post-softmax = 0.0112\n",
      "  expert 34: logit = -0.2967, post-softmax = 0.0332\n",
      "  expert 35: logit = -1.7058, post-softmax = 0.0081\n",
      "  expert 36: logit = -0.7496, post-softmax = 0.0211\n",
      "  expert 37: logit = -1.7332, post-softmax = 0.0079\n",
      "  expert 38: logit = -1.2090, post-softmax = 0.0133\n",
      "  expert 39: logit = -1.0109, post-softmax = 0.0163\n",
      "  expert 40: logit = -2.4584, post-softmax = 0.0038\n",
      "  expert 41: logit = -1.9432, post-softmax = 0.0064\n",
      "  expert 42: logit = -2.7524, post-softmax = 0.0028\n",
      "  expert 43: logit = -2.0772, post-softmax = 0.0056\n",
      "  expert 44: logit = -1.5338, post-softmax = 0.0096\n",
      "  expert 45: logit = -1.7318, post-softmax = 0.0079\n",
      "  expert 46: logit = -2.9761, post-softmax = 0.0023\n",
      "  expert 47: logit = -1.7725, post-softmax = 0.0076\n",
      "  expert 48: logit = -0.4941, post-softmax = 0.0273\n",
      "  expert 49: logit = -1.7741, post-softmax = 0.0076\n",
      "  expert 50: logit = -1.3478, post-softmax = 0.0116\n",
      "  expert 51: logit = -1.8355, post-softmax = 0.0071\n",
      "  expert 52: logit = 0.6849, post-softmax = 0.0886\n",
      "  expert 53: logit = -1.5449, post-softmax = 0.0095\n",
      "  expert 54: logit = -4.1833, post-softmax = 0.0007\n",
      "  expert 55: logit = -3.4124, post-softmax = 0.0015\n",
      "  expert 56: logit = -2.2732, post-softmax = 0.0046\n",
      "  expert 57: logit = -1.4255, post-softmax = 0.0107\n",
      "  expert 58: logit = 0.3346, post-softmax = 0.0624\n",
      "  expert 59: logit = -0.0276, post-softmax = 0.0435\n",
      "  expert 60: logit = 0.0660, post-softmax = 0.0477\n",
      "  expert 61: logit = -2.6278, post-softmax = 0.0032\n",
      "  expert 62: logit = -2.4637, post-softmax = 0.0038\n",
      "  expert 63: logit = -3.0366, post-softmax = 0.0021\n",
      "\n",
      "\n",
      "Top 8 experts for each token:\n",
      "Token: 'What' (ID: 1276)\n",
      "  1. expert 12: probability = 0.2768\n",
      "  2. expert 63: probability = 0.1014\n",
      "  3. expert 28: probability = 0.0532\n",
      "  4. expert 11: probability = 0.0258\n",
      "  5. expert 4: probability = 0.0256\n",
      "  6. expert 50: probability = 0.0255\n",
      "  7. expert 52: probability = 0.0245\n",
      "  8. expert 37: probability = 0.0226\n",
      "\n",
      "Token: ''s' (ID: 434)\n",
      "  1. expert 62: probability = 0.0889\n",
      "  2. expert 15: probability = 0.0772\n",
      "  3. expert 24: probability = 0.0558\n",
      "  4. expert 63: probability = 0.0470\n",
      "  5. expert 52: probability = 0.0438\n",
      "  6. expert 50: probability = 0.0323\n",
      "  7. expert 9: probability = 0.0309\n",
      "  8. expert 18: probability = 0.0291\n",
      "\n",
      "Token: ' the' (ID: 253)\n",
      "  1. expert 55: probability = 0.0791\n",
      "  2. expert 21: probability = 0.0535\n",
      "  3. expert 7: probability = 0.0535\n",
      "  4. expert 20: probability = 0.0514\n",
      "  5. expert 51: probability = 0.0360\n",
      "  6. expert 50: probability = 0.0335\n",
      "  7. expert 25: probability = 0.0319\n",
      "  8. expert 18: probability = 0.0308\n",
      "\n",
      "Token: ' musical' (ID: 12256)\n",
      "  1. expert 5: probability = 0.1102\n",
      "  2. expert 59: probability = 0.0851\n",
      "  3. expert 55: probability = 0.0486\n",
      "  4. expert 27: probability = 0.0474\n",
      "  5. expert 23: probability = 0.0434\n",
      "  6. expert 14: probability = 0.0412\n",
      "  7. expert 21: probability = 0.0360\n",
      "  8. expert 2: probability = 0.0317\n",
      "\n",
      "Token: ' pitch' (ID: 11288)\n",
      "  1. expert 23: probability = 0.1304\n",
      "  2. expert 59: probability = 0.0663\n",
      "  3. expert 2: probability = 0.0645\n",
      "  4. expert 54: probability = 0.0574\n",
      "  5. expert 26: probability = 0.0444\n",
      "  6. expert 17: probability = 0.0374\n",
      "  7. expert 34: probability = 0.0373\n",
      "  8. expert 15: probability = 0.0306\n",
      "\n",
      "Token: ' of' (ID: 273)\n",
      "  1. expert 61: probability = 0.0742\n",
      "  2. expert 56: probability = 0.0641\n",
      "  3. expert 59: probability = 0.0486\n",
      "  4. expert 39: probability = 0.0467\n",
      "  5. expert 7: probability = 0.0452\n",
      "  6. expert 26: probability = 0.0431\n",
      "  7. expert 48: probability = 0.0413\n",
      "  8. expert 14: probability = 0.0371\n",
      "\n",
      "Token: ' that' (ID: 326)\n",
      "  1. expert 20: probability = 0.0743\n",
      "  2. expert 55: probability = 0.0699\n",
      "  3. expert 59: probability = 0.0645\n",
      "  4. expert 21: probability = 0.0569\n",
      "  5. expert 7: probability = 0.0525\n",
      "  6. expert 47: probability = 0.0478\n",
      "  7. expert 26: probability = 0.0453\n",
      "  8. expert 39: probability = 0.0448\n",
      "\n",
      "Token: ' note' (ID: 3877)\n",
      "  1. expert 47: probability = 0.0592\n",
      "  2. expert 23: probability = 0.0592\n",
      "  3. expert 2: probability = 0.0550\n",
      "  4. expert 15: probability = 0.0542\n",
      "  5. expert 59: probability = 0.0444\n",
      "  6. expert 62: probability = 0.0375\n",
      "  7. expert 17: probability = 0.0349\n",
      "  8. expert 54: probability = 0.0334\n",
      "\n",
      "Token: '?' (ID: 32)\n",
      "  1. expert 3: probability = 0.1167\n",
      "  2. expert 52: probability = 0.0886\n",
      "  3. expert 17: probability = 0.0797\n",
      "  4. expert 58: probability = 0.0624\n",
      "  5. expert 12: probability = 0.0487\n",
      "  6. expert 60: probability = 0.0477\n",
      "  7. expert 59: probability = 0.0435\n",
      "  8. expert 34: probability = 0.0332\n",
      "\n",
      "Analysis results saved to expert_routing_analysis_1.json\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What's the musical pitch of that note?\"\n",
    "last_layer_router_logits, analysis_results = analyze_expert_routing(input_text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input:\n",
      "Token: 'How', ID: 2347\n",
      "Token: ' will', ID: 588\n",
      "Token: ' you', ID: 368\n",
      "Token: ' pitch', ID: 11288\n",
      "Token: ' your', ID: 634\n",
      "Token: ' idea', ID: 2934\n",
      "Token: ' to', ID: 281\n",
      "Token: ' the', ID: 253\n",
      "Token: ' investors', ID: 12946\n",
      "Token: '?', ID: 32\n",
      "\n",
      "Input shape: torch.Size([1, 10])\n",
      "\n",
      "Router logits and probabilities for each token:\n",
      "Token: 'How' (ID: 2347)\n",
      "  expert 0: logit = -0.7544, post-softmax = 0.0205\n",
      "  expert 1: logit = -1.9735, post-softmax = 0.0060\n",
      "  expert 2: logit = -2.1020, post-softmax = 0.0053\n",
      "  expert 3: logit = -1.8291, post-softmax = 0.0070\n",
      "  expert 4: logit = -0.6528, post-softmax = 0.0227\n",
      "  expert 5: logit = -0.7290, post-softmax = 0.0210\n",
      "  expert 6: logit = -1.4088, post-softmax = 0.0106\n",
      "  expert 7: logit = -2.9429, post-softmax = 0.0023\n",
      "  expert 8: logit = -1.9219, post-softmax = 0.0064\n",
      "  expert 9: logit = -1.5357, post-softmax = 0.0094\n",
      "  expert 10: logit = -2.0978, post-softmax = 0.0053\n",
      "  expert 11: logit = -0.8646, post-softmax = 0.0183\n",
      "  expert 12: logit = 1.8388, post-softmax = 0.2737\n",
      "  expert 13: logit = -1.9655, post-softmax = 0.0061\n",
      "  expert 14: logit = -1.6195, post-softmax = 0.0086\n",
      "  expert 15: logit = -0.2930, post-softmax = 0.0325\n",
      "  expert 16: logit = -1.2409, post-softmax = 0.0126\n",
      "  expert 17: logit = -1.8568, post-softmax = 0.0068\n",
      "  expert 18: logit = -0.7915, post-softmax = 0.0197\n",
      "  expert 19: logit = -1.8686, post-softmax = 0.0067\n",
      "  expert 20: logit = -2.0029, post-softmax = 0.0059\n",
      "  expert 21: logit = -2.5284, post-softmax = 0.0035\n",
      "  expert 22: logit = -0.6473, post-softmax = 0.0228\n",
      "  expert 23: logit = -1.4112, post-softmax = 0.0106\n",
      "  expert 24: logit = -1.1452, post-softmax = 0.0138\n",
      "  expert 25: logit = -2.5688, post-softmax = 0.0033\n",
      "  expert 26: logit = -2.3729, post-softmax = 0.0041\n",
      "  expert 27: logit = -1.9904, post-softmax = 0.0059\n",
      "  expert 28: logit = -1.1546, post-softmax = 0.0137\n",
      "  expert 29: logit = -1.6478, post-softmax = 0.0084\n",
      "  expert 30: logit = -2.1887, post-softmax = 0.0049\n",
      "  expert 31: logit = -1.1243, post-softmax = 0.0141\n",
      "  expert 32: logit = -1.4464, post-softmax = 0.0102\n",
      "  expert 33: logit = -1.5548, post-softmax = 0.0092\n",
      "  expert 34: logit = -1.4556, post-softmax = 0.0102\n",
      "  expert 35: logit = -1.7209, post-softmax = 0.0078\n",
      "  expert 36: logit = -1.8763, post-softmax = 0.0067\n",
      "  expert 37: logit = -0.2741, post-softmax = 0.0331\n",
      "  expert 38: logit = -1.1467, post-softmax = 0.0138\n",
      "  expert 39: logit = -1.1852, post-softmax = 0.0133\n",
      "  expert 40: logit = -0.9836, post-softmax = 0.0163\n",
      "  expert 41: logit = -1.3029, post-softmax = 0.0118\n",
      "  expert 42: logit = -2.3369, post-softmax = 0.0042\n",
      "  expert 43: logit = -1.4181, post-softmax = 0.0105\n",
      "  expert 44: logit = -2.2866, post-softmax = 0.0044\n",
      "  expert 45: logit = -1.8333, post-softmax = 0.0070\n",
      "  expert 46: logit = -2.1637, post-softmax = 0.0050\n",
      "  expert 47: logit = -2.4528, post-softmax = 0.0037\n",
      "  expert 48: logit = -2.2759, post-softmax = 0.0045\n",
      "  expert 49: logit = -2.7716, post-softmax = 0.0027\n",
      "  expert 50: logit = -0.8040, post-softmax = 0.0195\n",
      "  expert 51: logit = -1.8957, post-softmax = 0.0065\n",
      "  expert 52: logit = -0.4554, post-softmax = 0.0276\n",
      "  expert 53: logit = -1.8263, post-softmax = 0.0070\n",
      "  expert 54: logit = -2.3530, post-softmax = 0.0041\n",
      "  expert 55: logit = -2.4330, post-softmax = 0.0038\n",
      "  expert 56: logit = -1.8318, post-softmax = 0.0070\n",
      "  expert 57: logit = -2.3202, post-softmax = 0.0043\n",
      "  expert 58: logit = -1.9926, post-softmax = 0.0059\n",
      "  expert 59: logit = -1.9073, post-softmax = 0.0065\n",
      "  expert 60: logit = -1.8051, post-softmax = 0.0072\n",
      "  expert 61: logit = -2.3315, post-softmax = 0.0042\n",
      "  expert 62: logit = -0.1471, post-softmax = 0.0376\n",
      "  expert 63: logit = 0.5008, post-softmax = 0.0718\n",
      "\n",
      "Token: ' will' (ID: 588)\n",
      "  expert 0: logit = -1.8871, post-softmax = 0.0119\n",
      "  expert 1: logit = -2.4131, post-softmax = 0.0070\n",
      "  expert 2: logit = -4.1954, post-softmax = 0.0012\n",
      "  expert 3: logit = -1.9459, post-softmax = 0.0112\n",
      "  expert 4: logit = -1.1484, post-softmax = 0.0248\n",
      "  expert 5: logit = -2.9248, post-softmax = 0.0042\n",
      "  expert 6: logit = -2.7665, post-softmax = 0.0049\n",
      "  expert 7: logit = -0.7061, post-softmax = 0.0386\n",
      "  expert 8: logit = -1.7617, post-softmax = 0.0134\n",
      "  expert 9: logit = -1.5818, post-softmax = 0.0161\n",
      "  expert 10: logit = -2.8805, post-softmax = 0.0044\n",
      "  expert 11: logit = -2.2477, post-softmax = 0.0083\n",
      "  expert 12: logit = -0.9678, post-softmax = 0.0297\n",
      "  expert 13: logit = -2.9160, post-softmax = 0.0042\n",
      "  expert 14: logit = -1.8378, post-softmax = 0.0125\n",
      "  expert 15: logit = -2.8435, post-softmax = 0.0046\n",
      "  expert 16: logit = -1.2784, post-softmax = 0.0218\n",
      "  expert 17: logit = -1.9707, post-softmax = 0.0109\n",
      "  expert 18: logit = -1.1706, post-softmax = 0.0243\n",
      "  expert 19: logit = -2.7127, post-softmax = 0.0052\n",
      "  expert 20: logit = -2.1934, post-softmax = 0.0087\n",
      "  expert 21: logit = -1.1465, post-softmax = 0.0249\n",
      "  expert 22: logit = -1.6842, post-softmax = 0.0145\n",
      "  expert 23: logit = -3.4977, post-softmax = 0.0024\n",
      "  expert 24: logit = -1.0698, post-softmax = 0.0268\n",
      "  expert 25: logit = -0.5978, post-softmax = 0.0430\n",
      "  expert 26: logit = -1.0407, post-softmax = 0.0276\n",
      "  expert 27: logit = -0.9474, post-softmax = 0.0303\n",
      "  expert 28: logit = -2.0867, post-softmax = 0.0097\n",
      "  expert 29: logit = -1.6776, post-softmax = 0.0146\n",
      "  expert 30: logit = -1.4116, post-softmax = 0.0191\n",
      "  expert 31: logit = -2.1020, post-softmax = 0.0096\n",
      "  expert 32: logit = -1.5625, post-softmax = 0.0164\n",
      "  expert 33: logit = -2.0590, post-softmax = 0.0100\n",
      "  expert 34: logit = -1.2515, post-softmax = 0.0224\n",
      "  expert 35: logit = -2.2666, post-softmax = 0.0081\n",
      "  expert 36: logit = -2.8889, post-softmax = 0.0044\n",
      "  expert 37: logit = -1.3169, post-softmax = 0.0210\n",
      "  expert 38: logit = -0.8276, post-softmax = 0.0342\n",
      "  expert 39: logit = -1.4423, post-softmax = 0.0185\n",
      "  expert 40: logit = -3.1045, post-softmax = 0.0035\n",
      "  expert 41: logit = -3.2927, post-softmax = 0.0029\n",
      "  expert 42: logit = -1.4698, post-softmax = 0.0180\n",
      "  expert 43: logit = -2.7324, post-softmax = 0.0051\n",
      "  expert 44: logit = -2.3855, post-softmax = 0.0072\n",
      "  expert 45: logit = -2.9012, post-softmax = 0.0043\n",
      "  expert 46: logit = -3.0444, post-softmax = 0.0037\n",
      "  expert 47: logit = -3.0820, post-softmax = 0.0036\n",
      "  expert 48: logit = -2.0747, post-softmax = 0.0098\n",
      "  expert 49: logit = -0.9361, post-softmax = 0.0307\n",
      "  expert 50: logit = -1.4888, post-softmax = 0.0177\n",
      "  expert 51: logit = -0.4227, post-softmax = 0.0513\n",
      "  expert 52: logit = -1.6174, post-softmax = 0.0155\n",
      "  expert 53: logit = -2.7191, post-softmax = 0.0052\n",
      "  expert 54: logit = -4.0619, post-softmax = 0.0013\n",
      "  expert 55: logit = -2.2977, post-softmax = 0.0079\n",
      "  expert 56: logit = -0.2840, post-softmax = 0.0589\n",
      "  expert 57: logit = -2.1403, post-softmax = 0.0092\n",
      "  expert 58: logit = -2.6087, post-softmax = 0.0058\n",
      "  expert 59: logit = -1.4698, post-softmax = 0.0180\n",
      "  expert 60: logit = -2.6127, post-softmax = 0.0057\n",
      "  expert 61: logit = -0.0164, post-softmax = 0.0770\n",
      "  expert 62: logit = -2.8756, post-softmax = 0.0044\n",
      "  expert 63: logit = -2.2735, post-softmax = 0.0081\n",
      "\n",
      "Token: ' you' (ID: 368)\n",
      "  expert 0: logit = -1.6610, post-softmax = 0.0063\n",
      "  expert 1: logit = -1.8043, post-softmax = 0.0055\n",
      "  expert 2: logit = -3.1810, post-softmax = 0.0014\n",
      "  expert 3: logit = -2.1578, post-softmax = 0.0038\n",
      "  expert 4: logit = 1.1927, post-softmax = 0.1092\n",
      "  expert 5: logit = -1.8463, post-softmax = 0.0052\n",
      "  expert 6: logit = -1.1514, post-softmax = 0.0105\n",
      "  expert 7: logit = -3.0913, post-softmax = 0.0015\n",
      "  expert 8: logit = -0.9728, post-softmax = 0.0125\n",
      "  expert 9: logit = -1.0632, post-softmax = 0.0114\n",
      "  expert 10: logit = 0.7884, post-softmax = 0.0729\n",
      "  expert 11: logit = 0.8015, post-softmax = 0.0738\n",
      "  expert 12: logit = -0.5675, post-softmax = 0.0188\n",
      "  expert 13: logit = 0.9072, post-softmax = 0.0821\n",
      "  expert 14: logit = -2.9189, post-softmax = 0.0018\n",
      "  expert 15: logit = -2.0382, post-softmax = 0.0043\n",
      "  expert 16: logit = -1.4547, post-softmax = 0.0077\n",
      "  expert 17: logit = -1.2897, post-softmax = 0.0091\n",
      "  expert 18: logit = -0.6198, post-softmax = 0.0178\n",
      "  expert 19: logit = -1.3294, post-softmax = 0.0088\n",
      "  expert 20: logit = -2.3318, post-softmax = 0.0032\n",
      "  expert 21: logit = -3.8127, post-softmax = 0.0007\n",
      "  expert 22: logit = -1.5514, post-softmax = 0.0070\n",
      "  expert 23: logit = -3.5110, post-softmax = 0.0010\n",
      "  expert 24: logit = -0.0106, post-softmax = 0.0328\n",
      "  expert 25: logit = -2.4441, post-softmax = 0.0029\n",
      "  expert 26: logit = -3.0693, post-softmax = 0.0015\n",
      "  expert 27: logit = -2.3863, post-softmax = 0.0030\n",
      "  expert 28: logit = -1.1797, post-softmax = 0.0102\n",
      "  expert 29: logit = -0.8138, post-softmax = 0.0147\n",
      "  expert 30: logit = -1.0853, post-softmax = 0.0112\n",
      "  expert 31: logit = -2.2344, post-softmax = 0.0035\n",
      "  expert 32: logit = -1.5368, post-softmax = 0.0071\n",
      "  expert 33: logit = -0.5733, post-softmax = 0.0187\n",
      "  expert 34: logit = -0.8457, post-softmax = 0.0142\n",
      "  expert 35: logit = -1.3666, post-softmax = 0.0084\n",
      "  expert 36: logit = -2.5421, post-softmax = 0.0026\n",
      "  expert 37: logit = -1.2347, post-softmax = 0.0096\n",
      "  expert 38: logit = -2.1966, post-softmax = 0.0037\n",
      "  expert 39: logit = -0.9379, post-softmax = 0.0130\n",
      "  expert 40: logit = -1.8908, post-softmax = 0.0050\n",
      "  expert 41: logit = -2.6348, post-softmax = 0.0024\n",
      "  expert 42: logit = -1.2223, post-softmax = 0.0098\n",
      "  expert 43: logit = -2.2865, post-softmax = 0.0034\n",
      "  expert 44: logit = -1.0525, post-softmax = 0.0116\n",
      "  expert 45: logit = -0.8443, post-softmax = 0.0142\n",
      "  expert 46: logit = 0.8670, post-softmax = 0.0788\n",
      "  expert 47: logit = -1.9554, post-softmax = 0.0047\n",
      "  expert 48: logit = -0.9838, post-softmax = 0.0124\n",
      "  expert 49: logit = -2.2902, post-softmax = 0.0034\n",
      "  expert 50: logit = 0.4096, post-softmax = 0.0499\n",
      "  expert 51: logit = -0.0994, post-softmax = 0.0300\n",
      "  expert 52: logit = -0.7563, post-softmax = 0.0155\n",
      "  expert 53: logit = -1.4712, post-softmax = 0.0076\n",
      "  expert 54: logit = -1.2059, post-softmax = 0.0099\n",
      "  expert 55: logit = -3.4912, post-softmax = 0.0010\n",
      "  expert 56: logit = -2.3219, post-softmax = 0.0032\n",
      "  expert 57: logit = -1.4921, post-softmax = 0.0074\n",
      "  expert 58: logit = -3.7225, post-softmax = 0.0008\n",
      "  expert 59: logit = -1.2638, post-softmax = 0.0094\n",
      "  expert 60: logit = -2.7214, post-softmax = 0.0022\n",
      "  expert 61: logit = -4.0529, post-softmax = 0.0006\n",
      "  expert 62: logit = -1.7819, post-softmax = 0.0056\n",
      "  expert 63: logit = 0.8544, post-softmax = 0.0778\n",
      "\n",
      "Token: ' pitch' (ID: 11288)\n",
      "  expert 0: logit = -2.0331, post-softmax = 0.0094\n",
      "  expert 1: logit = -2.3882, post-softmax = 0.0066\n",
      "  expert 2: logit = -1.2091, post-softmax = 0.0213\n",
      "  expert 3: logit = -1.8323, post-softmax = 0.0114\n",
      "  expert 4: logit = -2.4147, post-softmax = 0.0064\n",
      "  expert 5: logit = -1.8968, post-softmax = 0.0107\n",
      "  expert 6: logit = -3.2621, post-softmax = 0.0027\n",
      "  expert 7: logit = -0.7573, post-softmax = 0.0335\n",
      "  expert 8: logit = -1.6804, post-softmax = 0.0133\n",
      "  expert 9: logit = -1.8756, post-softmax = 0.0110\n",
      "  expert 10: logit = -3.4990, post-softmax = 0.0022\n",
      "  expert 11: logit = -3.5449, post-softmax = 0.0021\n",
      "  expert 12: logit = -1.6434, post-softmax = 0.0138\n",
      "  expert 13: logit = -3.4405, post-softmax = 0.0023\n",
      "  expert 14: logit = -1.9124, post-softmax = 0.0106\n",
      "  expert 15: logit = -2.7492, post-softmax = 0.0046\n",
      "  expert 16: logit = -2.0633, post-softmax = 0.0091\n",
      "  expert 17: logit = -1.7239, post-softmax = 0.0127\n",
      "  expert 18: logit = -0.8288, post-softmax = 0.0312\n",
      "  expert 19: logit = -1.7181, post-softmax = 0.0128\n",
      "  expert 20: logit = -2.2576, post-softmax = 0.0075\n",
      "  expert 21: logit = -1.4083, post-softmax = 0.0175\n",
      "  expert 22: logit = 0.3609, post-softmax = 0.1025\n",
      "  expert 23: logit = -1.9096, post-softmax = 0.0106\n",
      "  expert 24: logit = -0.5063, post-softmax = 0.0431\n",
      "  expert 25: logit = -0.6010, post-softmax = 0.0392\n",
      "  expert 26: logit = -1.1200, post-softmax = 0.0233\n",
      "  expert 27: logit = -0.5087, post-softmax = 0.0430\n",
      "  expert 28: logit = -2.5768, post-softmax = 0.0054\n",
      "  expert 29: logit = -1.7447, post-softmax = 0.0125\n",
      "  expert 30: logit = -1.2815, post-softmax = 0.0198\n",
      "  expert 31: logit = -1.6804, post-softmax = 0.0133\n",
      "  expert 32: logit = -1.8761, post-softmax = 0.0109\n",
      "  expert 33: logit = -2.4868, post-softmax = 0.0059\n",
      "  expert 34: logit = -1.6535, post-softmax = 0.0137\n",
      "  expert 35: logit = -2.1569, post-softmax = 0.0083\n",
      "  expert 36: logit = -1.8863, post-softmax = 0.0108\n",
      "  expert 37: logit = -2.5952, post-softmax = 0.0053\n",
      "  expert 38: logit = -1.2133, post-softmax = 0.0212\n",
      "  expert 39: logit = -1.2616, post-softmax = 0.0202\n",
      "  expert 40: logit = -3.3013, post-softmax = 0.0026\n",
      "  expert 41: logit = -2.9798, post-softmax = 0.0036\n",
      "  expert 42: logit = -1.8211, post-softmax = 0.0116\n",
      "  expert 43: logit = -2.3655, post-softmax = 0.0067\n",
      "  expert 44: logit = -0.8400, post-softmax = 0.0308\n",
      "  expert 45: logit = -2.8990, post-softmax = 0.0039\n",
      "  expert 46: logit = -3.6708, post-softmax = 0.0018\n",
      "  expert 47: logit = -0.9636, post-softmax = 0.0273\n",
      "  expert 48: logit = -1.4407, post-softmax = 0.0169\n",
      "  expert 49: logit = -1.3245, post-softmax = 0.0190\n",
      "  expert 50: logit = -2.4567, post-softmax = 0.0061\n",
      "  expert 51: logit = -0.4209, post-softmax = 0.0469\n",
      "  expert 52: logit = -1.7746, post-softmax = 0.0121\n",
      "  expert 53: logit = -2.2743, post-softmax = 0.0073\n",
      "  expert 54: logit = -2.7863, post-softmax = 0.0044\n",
      "  expert 55: logit = -2.6299, post-softmax = 0.0052\n",
      "  expert 56: logit = -0.5456, post-softmax = 0.0414\n",
      "  expert 57: logit = -2.1504, post-softmax = 0.0083\n",
      "  expert 58: logit = -2.2130, post-softmax = 0.0078\n",
      "  expert 59: logit = -0.9226, post-softmax = 0.0284\n",
      "  expert 60: logit = -2.6409, post-softmax = 0.0051\n",
      "  expert 61: logit = -0.7920, post-softmax = 0.0324\n",
      "  expert 62: logit = -2.8916, post-softmax = 0.0040\n",
      "  expert 63: logit = -2.7392, post-softmax = 0.0046\n",
      "\n",
      "Token: ' your' (ID: 634)\n",
      "  expert 0: logit = -2.0271, post-softmax = 0.0064\n",
      "  expert 1: logit = -2.1857, post-softmax = 0.0054\n",
      "  expert 2: logit = -3.3111, post-softmax = 0.0018\n",
      "  expert 3: logit = -1.4772, post-softmax = 0.0111\n",
      "  expert 4: logit = -2.5002, post-softmax = 0.0040\n",
      "  expert 5: logit = -2.0260, post-softmax = 0.0064\n",
      "  expert 6: logit = -1.6795, post-softmax = 0.0090\n",
      "  expert 7: logit = 0.2805, post-softmax = 0.0641\n",
      "  expert 8: logit = -1.0359, post-softmax = 0.0172\n",
      "  expert 9: logit = -1.7839, post-softmax = 0.0081\n",
      "  expert 10: logit = -4.2685, post-softmax = 0.0007\n",
      "  expert 11: logit = -3.4752, post-softmax = 0.0015\n",
      "  expert 12: logit = -1.3208, post-softmax = 0.0129\n",
      "  expert 13: logit = -4.1947, post-softmax = 0.0007\n",
      "  expert 14: logit = -0.5351, post-softmax = 0.0284\n",
      "  expert 15: logit = -3.6476, post-softmax = 0.0013\n",
      "  expert 16: logit = -2.3081, post-softmax = 0.0048\n",
      "  expert 17: logit = -1.4158, post-softmax = 0.0118\n",
      "  expert 18: logit = -1.1255, post-softmax = 0.0157\n",
      "  expert 19: logit = -1.2816, post-softmax = 0.0134\n",
      "  expert 20: logit = 0.1965, post-softmax = 0.0589\n",
      "  expert 21: logit = 0.2956, post-softmax = 0.0651\n",
      "  expert 22: logit = -0.6305, post-softmax = 0.0258\n",
      "  expert 23: logit = -2.9846, post-softmax = 0.0024\n",
      "  expert 24: logit = -0.9128, post-softmax = 0.0194\n",
      "  expert 25: logit = 0.0001, post-softmax = 0.0484\n",
      "  expert 26: logit = -0.7785, post-softmax = 0.0222\n",
      "  expert 27: logit = -0.0211, post-softmax = 0.0474\n",
      "  expert 28: logit = -2.4747, post-softmax = 0.0041\n",
      "  expert 29: logit = -1.6029, post-softmax = 0.0098\n",
      "  expert 30: logit = -1.2113, post-softmax = 0.0144\n",
      "  expert 31: logit = -1.8956, post-softmax = 0.0073\n",
      "  expert 32: logit = -1.1233, post-softmax = 0.0158\n",
      "  expert 33: logit = -2.0889, post-softmax = 0.0060\n",
      "  expert 34: logit = -1.1026, post-softmax = 0.0161\n",
      "  expert 35: logit = -1.6902, post-softmax = 0.0089\n",
      "  expert 36: logit = -2.5087, post-softmax = 0.0039\n",
      "  expert 37: logit = -0.7224, post-softmax = 0.0235\n",
      "  expert 38: logit = -0.7703, post-softmax = 0.0224\n",
      "  expert 39: logit = -0.6948, post-softmax = 0.0242\n",
      "  expert 40: logit = -2.1396, post-softmax = 0.0057\n",
      "  expert 41: logit = -2.3654, post-softmax = 0.0045\n",
      "  expert 42: logit = -0.7101, post-softmax = 0.0238\n",
      "  expert 43: logit = -2.6066, post-softmax = 0.0036\n",
      "  expert 44: logit = -1.3090, post-softmax = 0.0131\n",
      "  expert 45: logit = -2.5504, post-softmax = 0.0038\n",
      "  expert 46: logit = -4.7927, post-softmax = 0.0004\n",
      "  expert 47: logit = -2.9407, post-softmax = 0.0026\n",
      "  expert 48: logit = -1.3006, post-softmax = 0.0132\n",
      "  expert 49: logit = -0.9159, post-softmax = 0.0194\n",
      "  expert 50: logit = -1.8209, post-softmax = 0.0078\n",
      "  expert 51: logit = 0.2210, post-softmax = 0.0604\n",
      "  expert 52: logit = -1.5117, post-softmax = 0.0107\n",
      "  expert 53: logit = -1.4789, post-softmax = 0.0110\n",
      "  expert 54: logit = -4.1009, post-softmax = 0.0008\n",
      "  expert 55: logit = 0.4470, post-softmax = 0.0757\n",
      "  expert 56: logit = -2.3734, post-softmax = 0.0045\n",
      "  expert 57: logit = -2.5833, post-softmax = 0.0037\n",
      "  expert 58: logit = -3.2980, post-softmax = 0.0018\n",
      "  expert 59: logit = -0.2154, post-softmax = 0.0390\n",
      "  expert 60: logit = -3.4490, post-softmax = 0.0015\n",
      "  expert 61: logit = -1.7009, post-softmax = 0.0088\n",
      "  expert 62: logit = -3.7015, post-softmax = 0.0012\n",
      "  expert 63: logit = -1.3920, post-softmax = 0.0120\n",
      "\n",
      "Token: ' idea' (ID: 2934)\n",
      "  expert 0: logit = -1.5373, post-softmax = 0.0150\n",
      "  expert 1: logit = -2.1375, post-softmax = 0.0082\n",
      "  expert 2: logit = 0.0352, post-softmax = 0.0722\n",
      "  expert 3: logit = -1.5570, post-softmax = 0.0147\n",
      "  expert 4: logit = -1.7626, post-softmax = 0.0120\n",
      "  expert 5: logit = -1.3805, post-softmax = 0.0175\n",
      "  expert 6: logit = -2.1584, post-softmax = 0.0081\n",
      "  expert 7: logit = -3.8310, post-softmax = 0.0015\n",
      "  expert 8: logit = -1.3726, post-softmax = 0.0177\n",
      "  expert 9: logit = -1.4842, post-softmax = 0.0158\n",
      "  expert 10: logit = -2.9826, post-softmax = 0.0035\n",
      "  expert 11: logit = -1.5131, post-softmax = 0.0154\n",
      "  expert 12: logit = -1.4429, post-softmax = 0.0165\n",
      "  expert 13: logit = -2.7697, post-softmax = 0.0044\n",
      "  expert 14: logit = -2.8815, post-softmax = 0.0039\n",
      "  expert 15: logit = -0.6612, post-softmax = 0.0360\n",
      "  expert 16: logit = -0.9646, post-softmax = 0.0266\n",
      "  expert 17: logit = -1.3548, post-softmax = 0.0180\n",
      "  expert 18: logit = -1.2257, post-softmax = 0.0205\n",
      "  expert 19: logit = -1.4221, post-softmax = 0.0168\n",
      "  expert 20: logit = -2.1881, post-softmax = 0.0078\n",
      "  expert 21: logit = -4.1956, post-softmax = 0.0011\n",
      "  expert 22: logit = -0.4140, post-softmax = 0.0461\n",
      "  expert 23: logit = -0.7357, post-softmax = 0.0334\n",
      "  expert 24: logit = -0.7378, post-softmax = 0.0333\n",
      "  expert 25: logit = -1.4076, post-softmax = 0.0171\n",
      "  expert 26: logit = -2.5757, post-softmax = 0.0053\n",
      "  expert 27: logit = -1.9613, post-softmax = 0.0098\n",
      "  expert 28: logit = -1.8093, post-softmax = 0.0114\n",
      "  expert 29: logit = -1.5888, post-softmax = 0.0142\n",
      "  expert 30: logit = -1.4313, post-softmax = 0.0167\n",
      "  expert 31: logit = -1.7229, post-softmax = 0.0124\n",
      "  expert 32: logit = -2.0398, post-softmax = 0.0091\n",
      "  expert 33: logit = -1.4962, post-softmax = 0.0156\n",
      "  expert 34: logit = -1.2384, post-softmax = 0.0202\n",
      "  expert 35: logit = -1.5282, post-softmax = 0.0151\n",
      "  expert 36: logit = -1.2789, post-softmax = 0.0194\n",
      "  expert 37: logit = -1.7763, post-softmax = 0.0118\n",
      "  expert 38: logit = -2.2386, post-softmax = 0.0074\n",
      "  expert 39: logit = -2.3095, post-softmax = 0.0069\n",
      "  expert 40: logit = -1.4622, post-softmax = 0.0162\n",
      "  expert 41: logit = -1.6523, post-softmax = 0.0134\n",
      "  expert 42: logit = -0.8017, post-softmax = 0.0313\n",
      "  expert 43: logit = -1.3555, post-softmax = 0.0180\n",
      "  expert 44: logit = -1.6020, post-softmax = 0.0140\n",
      "  expert 45: logit = -2.3969, post-softmax = 0.0063\n",
      "  expert 46: logit = -3.3962, post-softmax = 0.0023\n",
      "  expert 47: logit = -0.7072, post-softmax = 0.0344\n",
      "  expert 48: logit = -1.6641, post-softmax = 0.0132\n",
      "  expert 49: logit = -2.7791, post-softmax = 0.0043\n",
      "  expert 50: logit = -2.1632, post-softmax = 0.0080\n",
      "  expert 51: logit = -1.0893, post-softmax = 0.0235\n",
      "  expert 52: logit = -1.8148, post-softmax = 0.0114\n",
      "  expert 53: logit = -1.1320, post-softmax = 0.0225\n",
      "  expert 54: logit = -0.3319, post-softmax = 0.0500\n",
      "  expert 55: logit = -4.2717, post-softmax = 0.0010\n",
      "  expert 56: logit = -4.0942, post-softmax = 0.0012\n",
      "  expert 57: logit = -1.1589, post-softmax = 0.0219\n",
      "  expert 58: logit = -2.6188, post-softmax = 0.0051\n",
      "  expert 59: logit = -1.2577, post-softmax = 0.0198\n",
      "  expert 60: logit = -3.1421, post-softmax = 0.0030\n",
      "  expert 61: logit = -4.3511, post-softmax = 0.0009\n",
      "  expert 62: logit = -1.3380, post-softmax = 0.0183\n",
      "  expert 63: logit = -3.6498, post-softmax = 0.0018\n",
      "\n",
      "Token: ' to' (ID: 281)\n",
      "  expert 0: logit = -2.5976, post-softmax = 0.0045\n",
      "  expert 1: logit = -2.2459, post-softmax = 0.0064\n",
      "  expert 2: logit = -3.9949, post-softmax = 0.0011\n",
      "  expert 3: logit = -1.4131, post-softmax = 0.0146\n",
      "  expert 4: logit = 0.3319, post-softmax = 0.0837\n",
      "  expert 5: logit = -3.0679, post-softmax = 0.0028\n",
      "  expert 6: logit = -1.9555, post-softmax = 0.0085\n",
      "  expert 7: logit = -0.0544, post-softmax = 0.0569\n",
      "  expert 8: logit = -1.9653, post-softmax = 0.0084\n",
      "  expert 9: logit = -1.9079, post-softmax = 0.0089\n",
      "  expert 10: logit = -1.3532, post-softmax = 0.0155\n",
      "  expert 11: logit = -1.9681, post-softmax = 0.0084\n",
      "  expert 12: logit = -1.7164, post-softmax = 0.0108\n",
      "  expert 13: logit = -1.4140, post-softmax = 0.0146\n",
      "  expert 14: logit = -1.6769, post-softmax = 0.0112\n",
      "  expert 15: logit = -3.2135, post-softmax = 0.0024\n",
      "  expert 16: logit = -1.2652, post-softmax = 0.0170\n",
      "  expert 17: logit = -1.9539, post-softmax = 0.0085\n",
      "  expert 18: logit = -0.9781, post-softmax = 0.0226\n",
      "  expert 19: logit = -2.5069, post-softmax = 0.0049\n",
      "  expert 20: logit = -1.9142, post-softmax = 0.0089\n",
      "  expert 21: logit = -0.5251, post-softmax = 0.0355\n",
      "  expert 22: logit = -1.8309, post-softmax = 0.0096\n",
      "  expert 23: logit = -3.6565, post-softmax = 0.0016\n",
      "  expert 24: logit = -1.1671, post-softmax = 0.0187\n",
      "  expert 25: logit = 0.0532, post-softmax = 0.0633\n",
      "  expert 26: logit = -1.2280, post-softmax = 0.0176\n",
      "  expert 27: logit = -0.4724, post-softmax = 0.0375\n",
      "  expert 28: logit = -1.5002, post-softmax = 0.0134\n",
      "  expert 29: logit = -1.3626, post-softmax = 0.0154\n",
      "  expert 30: logit = -1.7774, post-softmax = 0.0102\n",
      "  expert 31: logit = -2.3520, post-softmax = 0.0057\n",
      "  expert 32: logit = -1.5446, post-softmax = 0.0128\n",
      "  expert 33: logit = -2.6162, post-softmax = 0.0044\n",
      "  expert 34: logit = -1.3440, post-softmax = 0.0157\n",
      "  expert 35: logit = -1.9673, post-softmax = 0.0084\n",
      "  expert 36: logit = -2.8863, post-softmax = 0.0034\n",
      "  expert 37: logit = -1.3123, post-softmax = 0.0162\n",
      "  expert 38: logit = -1.4289, post-softmax = 0.0144\n",
      "  expert 39: logit = -1.9657, post-softmax = 0.0084\n",
      "  expert 40: logit = -3.1041, post-softmax = 0.0027\n",
      "  expert 41: logit = -3.3517, post-softmax = 0.0021\n",
      "  expert 42: logit = -1.1892, post-softmax = 0.0183\n",
      "  expert 43: logit = -3.1612, post-softmax = 0.0025\n",
      "  expert 44: logit = -2.8733, post-softmax = 0.0034\n",
      "  expert 45: logit = -3.1031, post-softmax = 0.0027\n",
      "  expert 46: logit = -1.5153, post-softmax = 0.0132\n",
      "  expert 47: logit = -2.7293, post-softmax = 0.0039\n",
      "  expert 48: logit = -0.7956, post-softmax = 0.0271\n",
      "  expert 49: logit = -0.4992, post-softmax = 0.0365\n",
      "  expert 50: logit = -2.1144, post-softmax = 0.0073\n",
      "  expert 51: logit = 0.0227, post-softmax = 0.0614\n",
      "  expert 52: logit = -1.7275, post-softmax = 0.0107\n",
      "  expert 53: logit = -2.3863, post-softmax = 0.0055\n",
      "  expert 54: logit = -3.6520, post-softmax = 0.0016\n",
      "  expert 55: logit = -1.6769, post-softmax = 0.0112\n",
      "  expert 56: logit = 0.1789, post-softmax = 0.0718\n",
      "  expert 57: logit = -2.2778, post-softmax = 0.0062\n",
      "  expert 58: logit = -2.8986, post-softmax = 0.0033\n",
      "  expert 59: logit = -0.9601, post-softmax = 0.0230\n",
      "  expert 60: logit = -2.5043, post-softmax = 0.0049\n",
      "  expert 61: logit = -0.4295, post-softmax = 0.0391\n",
      "  expert 62: logit = -3.1855, post-softmax = 0.0025\n",
      "  expert 63: logit = -2.2188, post-softmax = 0.0065\n",
      "\n",
      "Token: ' the' (ID: 253)\n",
      "  expert 0: logit = -2.2896, post-softmax = 0.0039\n",
      "  expert 1: logit = -2.0262, post-softmax = 0.0051\n",
      "  expert 2: logit = -3.3506, post-softmax = 0.0013\n",
      "  expert 3: logit = -0.6749, post-softmax = 0.0196\n",
      "  expert 4: logit = -2.2573, post-softmax = 0.0040\n",
      "  expert 5: logit = -2.2762, post-softmax = 0.0040\n",
      "  expert 6: logit = -1.6802, post-softmax = 0.0072\n",
      "  expert 7: logit = 0.6375, post-softmax = 0.0728\n",
      "  expert 8: logit = -1.4371, post-softmax = 0.0091\n",
      "  expert 9: logit = -1.9875, post-softmax = 0.0053\n",
      "  expert 10: logit = -3.5324, post-softmax = 0.0011\n",
      "  expert 11: logit = -3.2486, post-softmax = 0.0015\n",
      "  expert 12: logit = -1.6065, post-softmax = 0.0077\n",
      "  expert 13: logit = -3.4951, post-softmax = 0.0012\n",
      "  expert 14: logit = -0.8538, post-softmax = 0.0164\n",
      "  expert 15: logit = -3.2875, post-softmax = 0.0014\n",
      "  expert 16: logit = -1.8067, post-softmax = 0.0063\n",
      "  expert 17: logit = -1.1636, post-softmax = 0.0120\n",
      "  expert 18: logit = -0.8028, post-softmax = 0.0172\n",
      "  expert 19: logit = -1.5497, post-softmax = 0.0082\n",
      "  expert 20: logit = -0.1043, post-softmax = 0.0347\n",
      "  expert 21: logit = 0.6476, post-softmax = 0.0736\n",
      "  expert 22: logit = -1.0532, post-softmax = 0.0134\n",
      "  expert 23: logit = -2.9823, post-softmax = 0.0020\n",
      "  expert 24: logit = -1.0901, post-softmax = 0.0129\n",
      "  expert 25: logit = 0.5395, post-softmax = 0.0660\n",
      "  expert 26: logit = -0.6585, post-softmax = 0.0199\n",
      "  expert 27: logit = 0.0500, post-softmax = 0.0405\n",
      "  expert 28: logit = -2.1360, post-softmax = 0.0045\n",
      "  expert 29: logit = -1.0707, post-softmax = 0.0132\n",
      "  expert 30: logit = -1.2620, post-softmax = 0.0109\n",
      "  expert 31: logit = -2.2407, post-softmax = 0.0041\n",
      "  expert 32: logit = -0.8090, post-softmax = 0.0171\n",
      "  expert 33: logit = -1.7609, post-softmax = 0.0066\n",
      "  expert 34: logit = -0.6281, post-softmax = 0.0205\n",
      "  expert 35: logit = -1.7398, post-softmax = 0.0068\n",
      "  expert 36: logit = -2.6916, post-softmax = 0.0026\n",
      "  expert 37: logit = -0.6826, post-softmax = 0.0195\n",
      "  expert 38: logit = -0.7402, post-softmax = 0.0184\n",
      "  expert 39: logit = -1.1665, post-softmax = 0.0120\n",
      "  expert 40: logit = -1.2907, post-softmax = 0.0106\n",
      "  expert 41: logit = -2.0490, post-softmax = 0.0050\n",
      "  expert 42: logit = 0.1967, post-softmax = 0.0469\n",
      "  expert 43: logit = -3.1350, post-softmax = 0.0017\n",
      "  expert 44: logit = -1.6451, post-softmax = 0.0074\n",
      "  expert 45: logit = -2.5675, post-softmax = 0.0030\n",
      "  expert 46: logit = -3.9539, post-softmax = 0.0007\n",
      "  expert 47: logit = -2.9479, post-softmax = 0.0020\n",
      "  expert 48: logit = -0.6223, post-softmax = 0.0207\n",
      "  expert 49: logit = 0.0841, post-softmax = 0.0419\n",
      "  expert 50: logit = -2.0177, post-softmax = 0.0051\n",
      "  expert 51: logit = 0.6911, post-softmax = 0.0768\n",
      "  expert 52: logit = -0.9452, post-softmax = 0.0150\n",
      "  expert 53: logit = -1.5383, post-softmax = 0.0083\n",
      "  expert 54: logit = -3.3920, post-softmax = 0.0013\n",
      "  expert 55: logit = 0.7552, post-softmax = 0.0819\n",
      "  expert 56: logit = -1.7038, post-softmax = 0.0070\n",
      "  expert 57: logit = -2.4505, post-softmax = 0.0033\n",
      "  expert 58: logit = -2.8886, post-softmax = 0.0021\n",
      "  expert 59: logit = -0.2252, post-softmax = 0.0307\n",
      "  expert 60: logit = -2.2464, post-softmax = 0.0041\n",
      "  expert 61: logit = -1.3951, post-softmax = 0.0095\n",
      "  expert 62: logit = -3.3278, post-softmax = 0.0014\n",
      "  expert 63: logit = -1.4533, post-softmax = 0.0090\n",
      "\n",
      "Token: ' investors' (ID: 12946)\n",
      "  expert 0: logit = -1.6865, post-softmax = 0.0125\n",
      "  expert 1: logit = -2.2842, post-softmax = 0.0069\n",
      "  expert 2: logit = 0.0436, post-softmax = 0.0706\n",
      "  expert 3: logit = -1.4708, post-softmax = 0.0155\n",
      "  expert 4: logit = -1.5011, post-softmax = 0.0151\n",
      "  expert 5: logit = -1.3212, post-softmax = 0.0180\n",
      "  expert 6: logit = -1.6649, post-softmax = 0.0128\n",
      "  expert 7: logit = -3.8333, post-softmax = 0.0015\n",
      "  expert 8: logit = -1.4453, post-softmax = 0.0159\n",
      "  expert 9: logit = -1.5155, post-softmax = 0.0148\n",
      "  expert 10: logit = -2.5416, post-softmax = 0.0053\n",
      "  expert 11: logit = -1.6685, post-softmax = 0.0127\n",
      "  expert 12: logit = -1.3232, post-softmax = 0.0180\n",
      "  expert 13: logit = -2.4016, post-softmax = 0.0061\n",
      "  expert 14: logit = -2.9123, post-softmax = 0.0037\n",
      "  expert 15: logit = -0.5483, post-softmax = 0.0390\n",
      "  expert 16: logit = -0.5789, post-softmax = 0.0379\n",
      "  expert 17: logit = -1.4671, post-softmax = 0.0156\n",
      "  expert 18: logit = -1.2169, post-softmax = 0.0200\n",
      "  expert 19: logit = -1.4864, post-softmax = 0.0153\n",
      "  expert 20: logit = -2.4914, post-softmax = 0.0056\n",
      "  expert 21: logit = -4.1310, post-softmax = 0.0011\n",
      "  expert 22: logit = -1.3791, post-softmax = 0.0170\n",
      "  expert 23: logit = -1.1995, post-softmax = 0.0204\n",
      "  expert 24: logit = -0.9873, post-softmax = 0.0252\n",
      "  expert 25: logit = -1.3193, post-softmax = 0.0181\n",
      "  expert 26: logit = -2.8918, post-softmax = 0.0037\n",
      "  expert 27: logit = -1.9750, post-softmax = 0.0094\n",
      "  expert 28: logit = -1.5782, post-softmax = 0.0139\n",
      "  expert 29: logit = -1.5017, post-softmax = 0.0150\n",
      "  expert 30: logit = -1.4173, post-softmax = 0.0164\n",
      "  expert 31: logit = -1.8921, post-softmax = 0.0102\n",
      "  expert 32: logit = -1.2994, post-softmax = 0.0184\n",
      "  expert 33: logit = -1.1572, post-softmax = 0.0212\n",
      "  expert 34: logit = -1.3497, post-softmax = 0.0175\n",
      "  expert 35: logit = -1.0353, post-softmax = 0.0240\n",
      "  expert 36: logit = -1.7466, post-softmax = 0.0118\n",
      "  expert 37: logit = -1.4333, post-softmax = 0.0161\n",
      "  expert 38: logit = -2.3582, post-softmax = 0.0064\n",
      "  expert 39: logit = -2.3243, post-softmax = 0.0066\n",
      "  expert 40: logit = -0.7488, post-softmax = 0.0319\n",
      "  expert 41: logit = -1.7946, post-softmax = 0.0112\n",
      "  expert 42: logit = -0.9658, post-softmax = 0.0257\n",
      "  expert 43: logit = -1.3914, post-softmax = 0.0168\n",
      "  expert 44: logit = -1.8535, post-softmax = 0.0106\n",
      "  expert 45: logit = -2.4347, post-softmax = 0.0059\n",
      "  expert 46: logit = -2.8582, post-softmax = 0.0039\n",
      "  expert 47: logit = -0.3298, post-softmax = 0.0486\n",
      "  expert 48: logit = -1.6480, post-softmax = 0.0130\n",
      "  expert 49: logit = -2.8652, post-softmax = 0.0038\n",
      "  expert 50: logit = -2.1734, post-softmax = 0.0077\n",
      "  expert 51: logit = -0.5598, post-softmax = 0.0386\n",
      "  expert 52: logit = -1.9512, post-softmax = 0.0096\n",
      "  expert 53: logit = -1.1255, post-softmax = 0.0219\n",
      "  expert 54: logit = -0.6161, post-softmax = 0.0365\n",
      "  expert 55: logit = -4.1337, post-softmax = 0.0011\n",
      "  expert 56: logit = -3.6252, post-softmax = 0.0018\n",
      "  expert 57: logit = -1.0674, post-softmax = 0.0232\n",
      "  expert 58: logit = -2.6123, post-softmax = 0.0050\n",
      "  expert 59: logit = -1.5579, post-softmax = 0.0142\n",
      "  expert 60: logit = -3.0232, post-softmax = 0.0033\n",
      "  expert 61: logit = -3.9987, post-softmax = 0.0012\n",
      "  expert 62: logit = -0.8740, post-softmax = 0.0282\n",
      "  expert 63: logit = -4.0865, post-softmax = 0.0011\n",
      "\n",
      "Token: '?' (ID: 32)\n",
      "  expert 0: logit = -1.6346, post-softmax = 0.0121\n",
      "  expert 1: logit = -1.2871, post-softmax = 0.0171\n",
      "  expert 2: logit = -3.4054, post-softmax = 0.0021\n",
      "  expert 3: logit = -0.5870, post-softmax = 0.0345\n",
      "  expert 4: logit = -0.3534, post-softmax = 0.0436\n",
      "  expert 5: logit = -1.2823, post-softmax = 0.0172\n",
      "  expert 6: logit = -1.5324, post-softmax = 0.0134\n",
      "  expert 7: logit = -3.4110, post-softmax = 0.0020\n",
      "  expert 8: logit = -1.2533, post-softmax = 0.0177\n",
      "  expert 9: logit = -1.2036, post-softmax = 0.0186\n",
      "  expert 10: logit = -1.9684, post-softmax = 0.0087\n",
      "  expert 11: logit = -1.5232, post-softmax = 0.0135\n",
      "  expert 12: logit = -0.2351, post-softmax = 0.0491\n",
      "  expert 13: logit = -2.2902, post-softmax = 0.0063\n",
      "  expert 14: logit = -2.4501, post-softmax = 0.0054\n",
      "  expert 15: logit = -3.6335, post-softmax = 0.0016\n",
      "  expert 16: logit = -1.8482, post-softmax = 0.0098\n",
      "  expert 17: logit = -1.0664, post-softmax = 0.0214\n",
      "  expert 18: logit = -1.5981, post-softmax = 0.0126\n",
      "  expert 19: logit = -1.6316, post-softmax = 0.0121\n",
      "  expert 20: logit = -3.2333, post-softmax = 0.0024\n",
      "  expert 21: logit = -3.6564, post-softmax = 0.0016\n",
      "  expert 22: logit = -1.6810, post-softmax = 0.0116\n",
      "  expert 23: logit = -2.7468, post-softmax = 0.0040\n",
      "  expert 24: logit = -0.4068, post-softmax = 0.0413\n",
      "  expert 25: logit = -0.5831, post-softmax = 0.0347\n",
      "  expert 26: logit = -1.7071, post-softmax = 0.0113\n",
      "  expert 27: logit = -1.6566, post-softmax = 0.0118\n",
      "  expert 28: logit = -2.1092, post-softmax = 0.0075\n",
      "  expert 29: logit = -1.1813, post-softmax = 0.0191\n",
      "  expert 30: logit = -1.3025, post-softmax = 0.0169\n",
      "  expert 31: logit = -2.0695, post-softmax = 0.0078\n",
      "  expert 32: logit = -1.8645, post-softmax = 0.0096\n",
      "  expert 33: logit = -1.4169, post-softmax = 0.0151\n",
      "  expert 34: logit = -1.2765, post-softmax = 0.0173\n",
      "  expert 35: logit = -1.6358, post-softmax = 0.0121\n",
      "  expert 36: logit = -1.2721, post-softmax = 0.0174\n",
      "  expert 37: logit = -1.8867, post-softmax = 0.0094\n",
      "  expert 38: logit = -1.8630, post-softmax = 0.0096\n",
      "  expert 39: logit = -2.0613, post-softmax = 0.0079\n",
      "  expert 40: logit = -1.8713, post-softmax = 0.0096\n",
      "  expert 41: logit = -1.7486, post-softmax = 0.0108\n",
      "  expert 42: logit = -1.5928, post-softmax = 0.0126\n",
      "  expert 43: logit = -1.5790, post-softmax = 0.0128\n",
      "  expert 44: logit = -1.3383, post-softmax = 0.0163\n",
      "  expert 45: logit = -3.6159, post-softmax = 0.0017\n",
      "  expert 46: logit = -1.7519, post-softmax = 0.0108\n",
      "  expert 47: logit = -2.4157, post-softmax = 0.0055\n",
      "  expert 48: logit = -2.5975, post-softmax = 0.0046\n",
      "  expert 49: logit = -1.7457, post-softmax = 0.0108\n",
      "  expert 50: logit = -2.4913, post-softmax = 0.0051\n",
      "  expert 51: logit = -0.4277, post-softmax = 0.0405\n",
      "  expert 52: logit = 0.4286, post-softmax = 0.0953\n",
      "  expert 53: logit = -1.8277, post-softmax = 0.0100\n",
      "  expert 54: logit = -4.1211, post-softmax = 0.0010\n",
      "  expert 55: logit = -3.9860, post-softmax = 0.0012\n",
      "  expert 56: logit = -2.8159, post-softmax = 0.0037\n",
      "  expert 57: logit = -1.5210, post-softmax = 0.0136\n",
      "  expert 58: logit = 0.0074, post-softmax = 0.0625\n",
      "  expert 59: logit = -1.3096, post-softmax = 0.0168\n",
      "  expert 60: logit = -0.0233, post-softmax = 0.0607\n",
      "  expert 61: logit = -2.6977, post-softmax = 0.0042\n",
      "  expert 62: logit = -3.8195, post-softmax = 0.0014\n",
      "  expert 63: logit = -3.8289, post-softmax = 0.0013\n",
      "\n",
      "\n",
      "Top 8 experts for each token:\n",
      "Token: 'How' (ID: 2347)\n",
      "  1. expert 12: probability = 0.2737\n",
      "  2. expert 63: probability = 0.0718\n",
      "  3. expert 62: probability = 0.0376\n",
      "  4. expert 37: probability = 0.0331\n",
      "  5. expert 15: probability = 0.0325\n",
      "  6. expert 52: probability = 0.0276\n",
      "  7. expert 22: probability = 0.0228\n",
      "  8. expert 4: probability = 0.0227\n",
      "\n",
      "Token: ' will' (ID: 588)\n",
      "  1. expert 61: probability = 0.0770\n",
      "  2. expert 56: probability = 0.0589\n",
      "  3. expert 51: probability = 0.0513\n",
      "  4. expert 25: probability = 0.0430\n",
      "  5. expert 7: probability = 0.0386\n",
      "  6. expert 38: probability = 0.0342\n",
      "  7. expert 49: probability = 0.0307\n",
      "  8. expert 27: probability = 0.0303\n",
      "\n",
      "Token: ' you' (ID: 368)\n",
      "  1. expert 4: probability = 0.1092\n",
      "  2. expert 13: probability = 0.0821\n",
      "  3. expert 46: probability = 0.0788\n",
      "  4. expert 63: probability = 0.0778\n",
      "  5. expert 11: probability = 0.0738\n",
      "  6. expert 10: probability = 0.0729\n",
      "  7. expert 50: probability = 0.0499\n",
      "  8. expert 24: probability = 0.0328\n",
      "\n",
      "Token: ' pitch' (ID: 11288)\n",
      "  1. expert 22: probability = 0.1025\n",
      "  2. expert 51: probability = 0.0469\n",
      "  3. expert 24: probability = 0.0431\n",
      "  4. expert 27: probability = 0.0430\n",
      "  5. expert 56: probability = 0.0414\n",
      "  6. expert 25: probability = 0.0392\n",
      "  7. expert 7: probability = 0.0335\n",
      "  8. expert 61: probability = 0.0324\n",
      "\n",
      "Token: ' your' (ID: 634)\n",
      "  1. expert 55: probability = 0.0757\n",
      "  2. expert 21: probability = 0.0651\n",
      "  3. expert 7: probability = 0.0641\n",
      "  4. expert 51: probability = 0.0604\n",
      "  5. expert 20: probability = 0.0589\n",
      "  6. expert 25: probability = 0.0484\n",
      "  7. expert 27: probability = 0.0474\n",
      "  8. expert 59: probability = 0.0390\n",
      "\n",
      "Token: ' idea' (ID: 2934)\n",
      "  1. expert 2: probability = 0.0722\n",
      "  2. expert 54: probability = 0.0500\n",
      "  3. expert 22: probability = 0.0461\n",
      "  4. expert 15: probability = 0.0360\n",
      "  5. expert 47: probability = 0.0344\n",
      "  6. expert 23: probability = 0.0334\n",
      "  7. expert 24: probability = 0.0333\n",
      "  8. expert 42: probability = 0.0313\n",
      "\n",
      "Token: ' to' (ID: 281)\n",
      "  1. expert 4: probability = 0.0837\n",
      "  2. expert 56: probability = 0.0718\n",
      "  3. expert 25: probability = 0.0633\n",
      "  4. expert 51: probability = 0.0614\n",
      "  5. expert 7: probability = 0.0569\n",
      "  6. expert 61: probability = 0.0391\n",
      "  7. expert 27: probability = 0.0375\n",
      "  8. expert 49: probability = 0.0365\n",
      "\n",
      "Token: ' the' (ID: 253)\n",
      "  1. expert 55: probability = 0.0819\n",
      "  2. expert 51: probability = 0.0768\n",
      "  3. expert 21: probability = 0.0736\n",
      "  4. expert 7: probability = 0.0728\n",
      "  5. expert 25: probability = 0.0660\n",
      "  6. expert 42: probability = 0.0469\n",
      "  7. expert 49: probability = 0.0419\n",
      "  8. expert 27: probability = 0.0405\n",
      "\n",
      "Token: ' investors' (ID: 12946)\n",
      "  1. expert 2: probability = 0.0706\n",
      "  2. expert 47: probability = 0.0486\n",
      "  3. expert 15: probability = 0.0390\n",
      "  4. expert 51: probability = 0.0386\n",
      "  5. expert 16: probability = 0.0379\n",
      "  6. expert 54: probability = 0.0365\n",
      "  7. expert 40: probability = 0.0319\n",
      "  8. expert 62: probability = 0.0282\n",
      "\n",
      "Token: '?' (ID: 32)\n",
      "  1. expert 52: probability = 0.0953\n",
      "  2. expert 58: probability = 0.0625\n",
      "  3. expert 60: probability = 0.0607\n",
      "  4. expert 12: probability = 0.0491\n",
      "  5. expert 4: probability = 0.0436\n",
      "  6. expert 24: probability = 0.0413\n",
      "  7. expert 51: probability = 0.0405\n",
      "  8. expert 25: probability = 0.0347\n",
      "\n",
      "Analysis results saved to expert_routing_analysis_2.json\n"
     ]
    }
   ],
   "source": [
    "input_text_2 = \"How will you pitch your idea to the investors?\"\n",
    "last_layer_router_logits_2, analysis_results_2 = analyze_expert_routing(input_text_2, model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_token_kl_divergence(json_file1, json_file2, target_token):\n",
    "    # Load JSON data from files\n",
    "    with open(json_file1, 'r') as f1, open(json_file2, 'r') as f2:\n",
    "        data1 = json.load(f1)\n",
    "        data2 = json.load(f2)\n",
    "    \n",
    "    # Find the target token in both inputs\n",
    "    token1 = next((t for t in data1['tokens'] if t['token'] == target_token or t['id'] == target_token), None)\n",
    "    token2 = next((t for t in data2['tokens'] if t['token'] == target_token or t['id'] == target_token), None)\n",
    "    \n",
    "    if not token1 or not token2:\n",
    "        raise ValueError(f\"Token '{target_token}' not found in one or both inputs\")\n",
    "    \n",
    "    # Get router probabilities for the target token\n",
    "    probs1 = np.array(token1['router_probability'])\n",
    "    probs2 = np.array(token2['router_probability'])\n",
    "    \n",
    "    # Ensure probabilities sum to 1\n",
    "    probs1 = probs1 / np.sum(probs1)\n",
    "    probs2 = probs2 / np.sum(probs2)\n",
    "    \n",
    "    # Calculate KL divergence for each expert\n",
    "    kl_divergences = kl_div(probs1, probs2)\n",
    "    \n",
    "    # Create a dictionary of expert-wise KL divergences\n",
    "    expert_kl = {f\"Expert_{i}\": kl for i, kl in enumerate(kl_divergences)}\n",
    "    \n",
    "    # Calculate the total KL divergence\n",
    "    total_kl = np.sum(kl_divergences)\n",
    "    \n",
    "    result = {\n",
    "        \"token\": target_token,\n",
    "        \"expert_kl_divergences\": expert_kl,\n",
    "        \"total_kl_divergence\": total_kl\n",
    "    }\n",
    "    \n",
    "    # Save the result as a JSON file\n",
    "    base_filename = \"kl_divergence_analysis\"\n",
    "    counter = 1\n",
    "    filename = f\"{base_filename}_{counter}.json\"\n",
    "    while os.path.exists(filename):\n",
    "        counter += 1\n",
    "        filename = f\"{base_filename}_{counter}.json\"\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "\n",
    "    print(f\"KL divergence analysis results saved to {filename}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL divergence analysis results saved to kl_divergence_analysis_1.json\n",
      "{\n",
      "  \"token\": 11288,\n",
      "  \"expert_kl_divergences\": {\n",
      "    \"Expert_0\": 0.013822967716602026,\n",
      "    \"Expert_1\": 0.0008376724012587114,\n",
      "    \"Expert_2\": 0.02823257784546524,\n",
      "    \"Expert_3\": 4.672694812931852e-06,\n",
      "    \"Expert_4\": 0.0013771582953915314,\n",
      "    \"Expert_5\": 0.0015263539795864131,\n",
      "    \"Expert_6\": 0.0002516992507180229,\n",
      "    \"Expert_7\": 0.020351488535727633,\n",
      "    \"Expert_8\": 0.0001573097508894613,\n",
      "    \"Expert_9\": 9.316885204474663e-05,\n",
      "    \"Expert_10\": 0.0021342830624215495,\n",
      "    \"Expert_11\": 5.6941361584724424e-05,\n",
      "    \"Expert_12\": 5.563769443583597e-06,\n",
      "    \"Expert_13\": 0.003731132175420142,\n",
      "    \"Expert_14\": 0.000656858469318105,\n",
      "    \"Expert_15\": 0.03211484009776097,\n",
      "    \"Expert_16\": 0.001914476454697011,\n",
      "    \"Expert_17\": 0.015629242566049195,\n",
      "    \"Expert_18\": 0.014715031691438046,\n",
      "    \"Expert_19\": 0.00485888986834053,\n",
      "    \"Expert_20\": 0.0003451279819312054,\n",
      "    \"Expert_21\": 0.007140513588838167,\n",
      "    \"Expert_22\": 0.04711764193658574,\n",
      "    \"Expert_23\": 0.20760350222545093,\n",
      "    \"Expert_24\": 0.011297229743954633,\n",
      "    \"Expert_25\": 0.01371199251625805,\n",
      "    \"Expert_26\": 0.00751144062084157,\n",
      "    \"Expert_27\": 0.011720147444392141,\n",
      "    \"Expert_28\": 0.006978517680536932,\n",
      "    \"Expert_29\": 0.0011820673447893015,\n",
      "    \"Expert_30\": 0.002850719777084884,\n",
      "    \"Expert_31\": 0.0028554872669581607,\n",
      "    \"Expert_32\": 0.006777143963150871,\n",
      "    \"Expert_33\": 0.00030801155487578374,\n",
      "    \"Expert_34\": 0.013784145691466389,\n",
      "    \"Expert_35\": 5.307774991017422e-05,\n",
      "    \"Expert_36\": 0.0005507112680224451,\n",
      "    \"Expert_37\": 0.001007966138944931,\n",
      "    \"Expert_38\": 0.00024789273059651687,\n",
      "    \"Expert_39\": 0.0017425175198138368,\n",
      "    \"Expert_40\": 0.000809092988603495,\n",
      "    \"Expert_41\": 0.0003756955921363249,\n",
      "    \"Expert_42\": 4.52197229727086e-07,\n",
      "    \"Expert_43\": 0.004052155240056249,\n",
      "    \"Expert_44\": 0.01793189511834603,\n",
      "    \"Expert_45\": 0.012262145245310416,\n",
      "    \"Expert_46\": 0.0003481677744776304,\n",
      "    \"Expert_47\": 0.001509509986095215,\n",
      "    \"Expert_48\": 0.0010374463797677529,\n",
      "    \"Expert_49\": 0.009596328321928535,\n",
      "    \"Expert_50\": 0.000423118269767442,\n",
      "    \"Expert_51\": 0.017694693379021863,\n",
      "    \"Expert_52\": 3.4511908311097433e-05,\n",
      "    \"Expert_53\": 0.00034222870957183356,\n",
      "    \"Expert_54\": 0.09430696626703843,\n",
      "    \"Expert_55\": 2.1138978102633148e-05,\n",
      "    \"Expert_56\": 0.035712118261437956,\n",
      "    \"Expert_57\": 0.0006389393412688966,\n",
      "    \"Expert_58\": 0.0006480355743881368,\n",
      "    \"Expert_59\": 0.018327163147653744,\n",
      "    \"Expert_60\": 0.0007794338292832206,\n",
      "    \"Expert_61\": 0.02734788574991684,\n",
      "    \"Expert_62\": 0.013192827167413285,\n",
      "    \"Expert_63\": 0.000996209822701319\n",
      "  },\n",
      "  \"total_kl_divergence\": 0.7456463428332013\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_file1 = \"expert_routing_analysis_1.json\"\n",
    "json_file2 = \"expert_routing_analysis_2.json\"\n",
    "target_token = 11288  # use token id\n",
    "\n",
    "result = calculate_token_kl_divergence(json_file1, json_file2, target_token)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorbar": {
          "title": {
           "text": "Probability"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ],
         "hovertemplate": "Token: %{y}<br>Expert: %{x}<br>Probability: %{z:.4f}<extra></extra>",
         "type": "heatmap",
         "x": [
          "Expert 0",
          "Expert 1",
          "Expert 2",
          "Expert 3",
          "Expert 4",
          "Expert 5",
          "Expert 6",
          "Expert 7",
          "Expert 8",
          "Expert 9",
          "Expert 10",
          "Expert 11",
          "Expert 12",
          "Expert 13",
          "Expert 14",
          "Expert 15",
          "Expert 16",
          "Expert 17",
          "Expert 18",
          "Expert 19",
          "Expert 20",
          "Expert 21",
          "Expert 22",
          "Expert 23",
          "Expert 24",
          "Expert 25",
          "Expert 26",
          "Expert 27",
          "Expert 28",
          "Expert 29",
          "Expert 30",
          "Expert 31",
          "Expert 32",
          "Expert 33",
          "Expert 34",
          "Expert 35",
          "Expert 36",
          "Expert 37",
          "Expert 38",
          "Expert 39",
          "Expert 40",
          "Expert 41",
          "Expert 42",
          "Expert 43",
          "Expert 44",
          "Expert 45",
          "Expert 46",
          "Expert 47",
          "Expert 48",
          "Expert 49",
          "Expert 50",
          "Expert 51",
          "Expert 52",
          "Expert 53",
          "Expert 54",
          "Expert 55",
          "Expert 56",
          "Expert 57",
          "Expert 58",
          "Expert 59",
          "Expert 60",
          "Expert 61",
          "Expert 62",
          "Expert 63"
         ],
         "xaxis": "x",
         "y": [
          "What",
          "'s",
          " the",
          " musical",
          " pitch",
          " of",
          " that",
          " note",
          "?"
         ],
         "yaxis": "y",
         "z": [
          [
           0.015111665241420269,
           0.007784102577716112,
           0.0073101706802845,
           0.004043440334498882,
           0.025615770369768143,
           0.020574502646923065,
           0.004704596009105444,
           0.0038766711950302124,
           0.007083327975124121,
           0.002604246838018298,
           0.004920676350593567,
           0.025849338620901108,
           0.2768186926841736,
           0.005627597216516733,
           0.017312467098236084,
           0.008856909349560738,
           0.009581612423062325,
           0.0079490402713418,
           0.017873413860797882,
           0.007449546828866005,
           0.017661435529589653,
           0.008337819017469883,
           0.02193087339401245,
           0.009585188701748848,
           0.015304338186979294,
           0.008312653750181198,
           0.002511139027774334,
           0.005069267936050892,
           0.05322440713644028,
           0.0024017419200390577,
           0.005776999983936548,
           0.007331961300224066,
           0.007539322134107351,
           0.004894396755844355,
           0.0071389442309737206,
           0.007540486752986908,
           0.006650189869105816,
           0.0226255115121603,
           0.007014729082584381,
           0.008225169964134693,
           0.018927671015262604,
           0.010267436504364014,
           0.0074157919734716415,
           0.005855346564203501,
           0.008280385285615921,
           0.0018465113826096058,
           0.00438714399933815,
           0.0037966750096529722,
           0.0018734793411567807,
           0.0030643928330391645,
           0.02548300102353096,
           0.006701168604195118,
           0.02447277493774891,
           0.004640442784875631,
           0.005353524349629879,
           0.01286168023943901,
           0.009867141023278236,
           0.004217548295855522,
           0.0049697658978402615,
           0.008957291953265667,
           0.003538569901138544,
           0.004030644427984953,
           0.007807541638612747,
           0.10135968029499054
          ],
          [
           0.013320308178663254,
           0.006680232938379049,
           0.0030983530450612307,
           0.009089695289731026,
           0.010813510976731777,
           0.0029745097272098064,
           0.008980323560535908,
           0.021172238513827324,
           0.01594330184161663,
           0.030909189954400063,
           0.023908505216240883,
           0.004147157073020935,
           0.02302057296037674,
           0.026651473715901375,
           0.015767795965075493,
           0.07717832177877426,
           0.011685817502439022,
           0.012122591957449913,
           0.02912149764597416,
           0.0034867904614657164,
           0.0037183696404099464,
           0.005991012789309025,
           0.00917558092623949,
           0.0035271726083010435,
           0.05582170933485031,
           0.013607172295451164,
           0.01273435354232788,
           0.015498701483011246,
           0.014078821055591106,
           0.01423153467476368,
           0.01977607049047947,
           0.0065040262416005135,
           0.011357968673110008,
           0.006155789364129305,
           0.013552078045904636,
           0.005388287361711264,
           0.0037437451537698507,
           0.004345497582107782,
           0.019193224608898163,
           0.017331469804048538,
           0.003686109557747841,
           0.0045392876490950584,
           0.006184619385749102,
           0.00360078364610672,
           0.006450172048062086,
           0.01881098747253418,
           0.015553690493106842,
           0.0031086746603250504,
           0.013624206185340881,
           0.018236272037029266,
           0.03229730948805809,
           0.01571386121213436,
           0.04382173717021942,
           0.005192443262785673,
           0.0036578241270035505,
           0.003616105765104294,
           0.009175511077046394,
           0.0033113316167145967,
           0.005379577167332172,
           0.021524397656321526,
           0.006359911989420652,
           0.014362940564751625,
           0.08894290030002594,
           0.04704445227980614
          ],
          [
           0.0041468762792646885,
           0.009049882180988789,
           0.0011903131380677223,
           0.013495919294655323,
           0.004899132065474987,
           0.0025902767665684223,
           0.0065014977008104324,
           0.05352140590548515,
           0.020084576681256294,
           0.016007306054234505,
           0.0008970023482106626,
           0.002341323299333453,
           0.0196659155189991,
           0.0010378664592280984,
           0.030008962377905846,
           0.001856910064816475,
           0.006733618676662445,
           0.013750724494457245,
           0.030815280973911285,
           0.00679480005055666,
           0.051401637494564056,
           0.053521547466516495,
           0.014117522165179253,
           0.0012931389501318336,
           0.029604213312268257,
           0.031894583255052567,
           0.023818710818886757,
           0.030706288293004036,
           0.004944855812937021,
           0.013829444535076618,
           0.022098861634731293,
           0.004780762828886509,
           0.024455351755023003,
           0.016119645908474922,
           0.01730765588581562,
           0.005690089426934719,
           0.0033451125491410494,
           0.028138281777501106,
           0.024401819333434105,
           0.021439852192997932,
           0.002296207705512643,
           0.0035424712114036083,
           0.0150666618719697,
           0.001680414890870452,
           0.007963198237121105,
           0.006029515992850065,
           0.000498828652780503,
           0.004096850752830505,
           0.009193167090415955,
           0.024472514167428017,
           0.03348023071885109,
           0.03598631173372269,
           0.028662214055657387,
           0.013530388474464417,
           0.0007317116833291948,
           0.07912188023328781,
           0.003116437466815114,
           0.004552911035716534,
           0.003238286590203643,
           0.03054024651646614,
           0.0032913885079324245,
           0.004626299254596233,
           0.0016300211427733302,
           0.014352838508784771
          ],
          [
           0.009077467024326324,
           0.004330396186560392,
           0.03167809545993805,
           0.004605587106198072,
           0.005713222082704306,
           0.11016592383384705,
           0.0038230339996516705,
           0.030519232153892517,
           0.013817296363413334,
           0.009302335791289806,
           0.0013177604414522648,
           0.005041142459958792,
           0.01741025224328041,
           0.001689275959506631,
           0.041191305965185165,
           0.0028391950763761997,
           0.004283614456653595,
           0.01302658673375845,
           0.012172519229352474,
           0.013233469799160957,
           0.027871327474713326,
           0.03595871850848198,
           0.01956082507967949,
           0.04339468106627464,
           0.021683059632778168,
           0.01959049142897129,
           0.022523624822497368,
           0.04737040400505066,
           0.011893636547029018,
           0.008071726188063622,
           0.013020765036344528,
           0.005459179170429707,
           0.0014446091372519732,
           0.007360152900218964,
           0.009224919602274895,
           0.003911164589226246,
           0.008365645073354244,
           0.004064757842570543,
           0.013034055009484291,
           0.012881046161055565,
           0.025754427537322044,
           0.0082790432497859,
           0.017110608518123627,
           0.0033477775286883116,
           0.007484673522412777,
           0.0032965412829071283,
           0.0006760684191249311,
           0.02657732553780079,
           0.004924959037452936,
           0.014766807667911053,
           0.005341519135981798,
           0.012473289854824543,
           0.01713058352470398,
           0.004327811766415834,
           0.016338642686605453,
           0.04862705245614052,
           0.0017561317654326558,
           0.0036340621300041676,
           0.005946004763245583,
           0.08514758199453354,
           0.0027091673109680414,
           0.0025659322272986174,
           0.0018123674672096968,
           0.008049090392887592
          ],
          [
           0.029576124623417854,
           0.0035369927063584328,
           0.06451857835054398,
           0.011110502295196056,
           0.011018936522305012,
           0.016930365934967995,
           0.003991979174315929,
           0.004312493372708559,
           0.011317877098917961,
           0.012410219758749008,
           0.005845326464623213,
           0.0025661864783614874,
           0.013422823511064053,
           0.007536577992141247,
           0.01449202187359333,
           0.030581992119550705,
           0.0038618457037955523,
           0.03742063045501709,
           0.006363200955092907,
           0.003435746068134904,
           0.009857802651822567,
           0.004302928224205971,
           0.02169918641448021,
           0.1303820013999939,
           0.015925802290439606,
           0.011392701417207718,
           0.04439307376742363,
           0.015441454946994781,
           0.01623990200459957,
           0.0074605862610042095,
           0.01020123716443777,
           0.022937169298529625,
           0.001346529577858746,
           0.004135432653129101,
           0.037279192358255386,
           0.009220135398209095,
           0.0075689260847866535,
           0.002410744782537222,
           0.018076013773679733,
           0.012440847232937813,
           0.004950686823576689,
           0.005402410868555307,
           0.011666657403111458,
           0.015336710959672928,
           0.004372215364128351,
           0.017307480797171593,
           0.003055153414607048,
           0.0187070369720459,
           0.011348636820912361,
           0.0034900882747024298,
           0.0085378997027874,
           0.012637770734727383,
           0.011212245561182499,
           0.005224223714321852,
           0.05737544223666191,
           0.004690834321081638,
           0.001269096857868135,
           0.005279433447867632,
           0.01120680384337902,
           0.06632398813962936,
           0.0025500899646431208,
           0.0011576921679079533,
           0.017996633425354958,
           0.001938725239597261
          ],
          [
           0.007134951185435057,
           0.006530672777444124,
           0.0013521412620320916,
           0.03352734073996544,
           0.008887257426977158,
           0.003680536989122629,
           0.00914771668612957,
           0.04515312612056732,
           0.01029896829277277,
           0.014770186506211758,
           0.0023679379373788834,
           0.004202122800052166,
           0.0215658787637949,
           0.002642706735059619,
           0.037111151963472366,
           0.002683693775907159,
           0.012293667532503605,
           0.02093665674328804,
           0.012861471623182297,
           0.0029128510504961014,
           0.010642255656421185,
           0.027732474729418755,
           0.014225603081285954,
           0.001881695119664073,
           0.0159590020775795,
           0.006747291423380375,
           0.04312984645366669,
           0.032805051654577255,
           0.005435798782855272,
           0.015679223462939262,
           0.010422326624393463,
           0.00646769255399704,
           0.011383386328816414,
           0.006038702558726072,
           0.029306737706065178,
           0.012368256226181984,
           0.00463701318949461,
           0.02348502166569233,
           0.02942766807973385,
           0.04668740555644035,
           0.0015421315329149365,
           0.002336828038096428,
           0.004030212294310331,
           0.004084082320332527,
           0.006306692957878113,
           0.017234576866030693,
           0.0016987419221550226,
           0.0030750292353332043,
           0.04126831889152527,
           0.022352883592247963,
           0.019631611183285713,
           0.014536610804498196,
           0.009907079860568047,
           0.01100238785147667,
           0.000769445498008281,
           0.007602043449878693,
           0.06412731111049652,
           0.011606873944401741,
           0.004647769499570131,
           0.048647794872522354,
           0.005234012380242348,
           0.07423250377178192,
           0.002886315109208226,
           0.006715153809636831
          ],
          [
           0.004642818588763475,
           0.004602882545441389,
           0.016947099938988686,
           0.0118188401684165,
           0.00590471550822258,
           0.0048519521951675415,
           0.0036357780918478966,
           0.05248866602778435,
           0.008655838668346405,
           0.006034456193447113,
           0.0014795138267800212,
           0.0041204155422747135,
           0.028848685324192047,
           0.001742738182656467,
           0.036775823682546616,
           0.003942179959267378,
           0.0036043138243258,
           0.01802549883723259,
           0.008475612848997116,
           0.007603879552334547,
           0.07432907074689865,
           0.05690140277147293,
           0.02566608414053917,
           0.006322705652564764,
           0.008952895179390907,
           0.005636480636894703,
           0.04526149109005928,
           0.0375383198261261,
           0.012502494268119335,
           0.008975541219115257,
           0.00768753606826067,
           0.003939027898013592,
           0.003708172356709838,
           0.010263161733746529,
           0.021596526727080345,
           0.005174243822693825,
           0.004843943286687136,
           0.01685672253370285,
           0.020956067368388176,
           0.044825442135334015,
           0.0037636924535036087,
           0.0029008991550654173,
           0.004733314737677574,
           0.001834040624089539,
           0.0057750362902879715,
           0.01645783893764019,
           0.0007487646653316915,
           0.04783429205417633,
           0.01174202375113964,
           0.015549864619970322,
           0.014067214913666248,
           0.00791911594569683,
           0.009301158599555492,
           0.0092976288869977,
           0.005418944638222456,
           0.0699348896741867,
           0.006284789182245731,
           0.003726884489879012,
           0.002767471130937338,
           0.06445714086294174,
           0.002273040823638439,
           0.0030658396426588297,
           0.003104035509750247,
           0.030903059989213943
          ],
          [
           0.015998119488358498,
           0.0047560324892401695,
           0.05497867241501808,
           0.020057640969753265,
           0.02471213974058628,
           0.009103803895413876,
           0.008389177732169628,
           0.0036057711113244295,
           0.010926371440291405,
           0.016670627519488335,
           0.014000511728227139,
           0.01340591162443161,
           0.024253519251942635,
           0.017184501513838768,
           0.007160678505897522,
           0.05423949658870697,
           0.014168182387948036,
           0.03494534268975258,
           0.016083940863609314,
           0.008198845200240612,
           0.004903377499431372,
           0.0016754287062212825,
           0.016804205253720284,
           0.0592394582927227,
           0.016514083370566368,
           0.003253675764426589,
           0.014108582399785519,
           0.008610861375927925,
           0.017840487882494926,
           0.011127153411507607,
           0.011031289584934711,
           0.009966029785573483,
           0.007787669077515602,
           0.014783530496060848,
           0.026069633662700653,
           0.012004764750599861,
           0.012490862980484962,
           0.008597873151302338,
           0.012256418354809284,
           0.012819500640034676,
           0.006809794809669256,
           0.006377173122018576,
           0.004060348495841026,
           0.01087944395840168,
           0.004507189616560936,
           0.024535078555345535,
           0.00919628981500864,
           0.059239886701107025,
           0.014919648878276348,
           0.0055283731780946255,
           0.024444270879030228,
           0.006794230081140995,
           0.010709255002439022,
           0.01146281324326992,
           0.03344345837831497,
           0.001528894528746605,
           0.0018457035766914487,
           0.009073684923350811,
           0.00826527364552021,
           0.044407717883586884,
           0.0058986721560359,
           0.0008420295780524611,
           0.03752778470516205,
           0.002978846663609147
          ],
          [
           0.006917444057762623,
           0.016041051596403122,
           0.0024162011686712503,
           0.11673018336296082,
           0.013144315220415592,
           0.004822908900678158,
           0.006313893478363752,
           0.002266018884256482,
           0.022468551993370056,
           0.013769912533462048,
           0.0024090022780001163,
           0.004921384621411562,
           0.048734311014413834,
           0.002306893467903137,
           0.00870267953723669,
           0.004797029308974743,
           0.005203885491937399,
           0.07969816029071808,
           0.008515260182321072,
           0.005118495784699917,
           0.0033607911318540573,
           0.0019998985808342695,
           0.00674680108204484,
           0.0028586077969521284,
           0.023822959512472153,
           0.003453453304246068,
           0.03098457306623459,
           0.012622875161468983,
           0.0082087442278862,
           0.015352152287960052,
           0.016056334599852562,
           0.0035399727057665586,
           0.006485732272267342,
           0.011187580414116383,
           0.03320860490202904,
           0.008114917203783989,
           0.02111302874982357,
           0.007895112968981266,
           0.013336374424397945,
           0.01625712588429451,
           0.0038231760263442993,
           0.006399948615580797,
           0.002849447075277567,
           0.005597167182713747,
           0.009637504816055298,
           0.007906562648713589,
           0.002278225962072611,
           0.007591369096189737,
           0.027259591966867447,
           0.007578769698739052,
           0.011607264168560505,
           0.00712772598490119,
           0.08862107992172241,
           0.009531174786388874,
           0.0006812321371398866,
           0.0014726624358445406,
           0.004601005930453539,
           0.010740075260400772,
           0.06243325024843216,
           0.043460994958877563,
           0.047724030911922455,
           0.0032272611279040575,
           0.0038028396666049957,
           0.0021444910671561956
          ]
         ]
        },
        {
         "colorbar": {
          "title": {
           "text": "Probability"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ],
         "hovertemplate": "Token: %{y}<br>Expert: %{x}<br>Probability: %{z:.4f}<extra></extra>",
         "type": "heatmap",
         "x": [
          "Expert 0",
          "Expert 1",
          "Expert 2",
          "Expert 3",
          "Expert 4",
          "Expert 5",
          "Expert 6",
          "Expert 7",
          "Expert 8",
          "Expert 9",
          "Expert 10",
          "Expert 11",
          "Expert 12",
          "Expert 13",
          "Expert 14",
          "Expert 15",
          "Expert 16",
          "Expert 17",
          "Expert 18",
          "Expert 19",
          "Expert 20",
          "Expert 21",
          "Expert 22",
          "Expert 23",
          "Expert 24",
          "Expert 25",
          "Expert 26",
          "Expert 27",
          "Expert 28",
          "Expert 29",
          "Expert 30",
          "Expert 31",
          "Expert 32",
          "Expert 33",
          "Expert 34",
          "Expert 35",
          "Expert 36",
          "Expert 37",
          "Expert 38",
          "Expert 39",
          "Expert 40",
          "Expert 41",
          "Expert 42",
          "Expert 43",
          "Expert 44",
          "Expert 45",
          "Expert 46",
          "Expert 47",
          "Expert 48",
          "Expert 49",
          "Expert 50",
          "Expert 51",
          "Expert 52",
          "Expert 53",
          "Expert 54",
          "Expert 55",
          "Expert 56",
          "Expert 57",
          "Expert 58",
          "Expert 59",
          "Expert 60",
          "Expert 61",
          "Expert 62",
          "Expert 63"
         ],
         "xaxis": "x2",
         "y": [
          "How",
          " will",
          " you",
          " pitch",
          " your",
          " idea",
          " to",
          " the",
          " investors",
          "?"
         ],
         "yaxis": "y2",
         "z": [
          [
           0.020467251539230347,
           0.006048060953617096,
           0.0053190793842077255,
           0.006987560074776411,
           0.022657515481114388,
           0.020995305851101875,
           0.010638904757797718,
           0.0022942074574530125,
           0.006368445232510567,
           0.009370619431138039,
           0.0053414334543049335,
           0.01833200827240944,
           0.2737162113189697,
           0.006096752360463142,
           0.008617652580142021,
           0.032469384372234344,
           0.012582926079630852,
           0.006796747446060181,
           0.019722476601600647,
           0.006717415526509285,
           0.005872784648090601,
           0.0034724073484539986,
           0.022782031446695328,
           0.01061305869370699,
           0.013847718015313148,
           0.0033348891884088516,
           0.004056534264236689,
           0.00594702921807766,
           0.013717669993638992,
           0.008376765996217728,
           0.004877206403762102,
           0.014138971455395222,
           0.010246263816952705,
           0.00919333565980196,
           0.010152173228561878,
           0.007786220405250788,
           0.006665832828730345,
           0.03308689221739769,
           0.013826699927449226,
           0.013304098509252071,
           0.01627649925649166,
           0.011826635338366032,
           0.004205607809126377,
           0.010539931245148182,
           0.00442217942327261,
           0.006958803161978722,
           0.005000893492251635,
           0.0037452424876391888,
           0.0044698347337543964,
           0.0027229555416852236,
           0.01947849430143833,
           0.006537683308124542,
           0.02760208211839199,
           0.007007137406617403,
           0.004138384945690632,
           0.003820013953372836,
           0.006969016045331955,
           0.004276059102267027,
           0.005933675449341536,
           0.006462490651756525,
           0.0071573820896446705,
           0.0042280820198357105,
           0.03756898269057274,
           0.07181339710950851
          ],
          [
           0.011854884214699268,
           0.007006282452493906,
           0.0011788284173235297,
           0.011178888380527496,
           0.024816570803523064,
           0.004200123716145754,
           0.004920458886772394,
           0.03861883655190468,
           0.013439016416668892,
           0.016088880598545074,
           0.004390405025333166,
           0.008266022428870201,
           0.029728123918175697,
           0.004237177316099405,
           0.012454897165298462,
           0.0045556556433439255,
           0.021791568025946617,
           0.010904253460466862,
           0.024270135909318924,
           0.005192559212446213,
           0.00872733723372221,
           0.02486264519393444,
           0.014522332698106766,
           0.0023684226907789707,
           0.0268461462110281,
           0.043036315590143204,
           0.02763788215816021,
           0.030340874567627907,
           0.009710040874779224,
           0.014617949724197388,
           0.019072849303483963,
           0.009562505409121513,
           0.016401035711169243,
           0.009982558898627758,
           0.022385237738490105,
           0.008111213333904743,
           0.004353521391749382,
           0.02096799574792385,
           0.034200794994831085,
           0.018496191129088402,
           0.003509143367409706,
           0.0029073082841932774,
           0.017995106056332588,
           0.00509116193279624,
           0.007202471140772104,
           0.0043003070168197155,
           0.003726547583937645,
           0.003589178901165724,
           0.009827477857470512,
           0.030684709548950195,
           0.01765541173517704,
           0.051272835582494736,
           0.015525750815868378,
           0.005158950109034777,
           0.0013471408747136593,
           0.007863388396799564,
           0.05890282988548279,
           0.00920312013477087,
           0.005761548411101103,
           0.017995530739426613,
           0.005738551262766123,
           0.0769764855504036,
           0.004411667585372925,
           0.008055957034230232
          ],
          [
           0.006291489582508802,
           0.005451425444334745,
           0.001376042258925736,
           0.0038280105218291283,
           0.1091642826795578,
           0.005227507092058659,
           0.010472682304680347,
           0.0015050804940983653,
           0.012520832009613514,
           0.011438978835940361,
           0.07286664843559265,
           0.07382825016975403,
           0.018778974190354347,
           0.08205621689558029,
           0.0017883834661915898,
           0.004314357414841652,
           0.007732978090643883,
           0.009120646864175797,
           0.017820803448557854,
           0.008765229023993015,
           0.0032169176265597343,
           0.000731581065338105,
           0.007020048331469297,
           0.0009892836678773165,
           0.032771509140729904,
           0.0028752521611750126,
           0.0015386976301670074,
           0.003046046243980527,
           0.010180402547121048,
           0.014678224921226501,
           0.011188412085175514,
           0.003545848885551095,
           0.007123562507331371,
           0.018669210374355316,
           0.01421829592436552,
           0.008445493876934052,
           0.0026067299768328667,
           0.009635725989937782,
           0.003682399168610573,
           0.012965074740350246,
           0.004999606870114803,
           0.0023759377654641867,
           0.0097562987357378,
           0.003365748096257448,
           0.011561829596757889,
           0.014237210154533386,
           0.07881958782672882,
           0.004687189590185881,
           0.012383589521050453,
           0.0033534590620547533,
           0.0498911589384079,
           0.029987286776304245,
           0.01554817520081997,
           0.0076065403409302235,
           0.009917407296597958,
           0.0010089980205520988,
           0.003248936031013727,
           0.007449218071997166,
           0.0008006930584087968,
           0.009359070099890232,
           0.0021789504680782557,
           0.0005753968725912273,
           0.005575111135840416,
           0.07783500850200653
          ],
          [
           0.009354858659207821,
           0.006558944936841726,
           0.021325306966900826,
           0.011435853317379951,
           0.0063871219754219055,
           0.010720719583332539,
           0.0027369847521185875,
           0.03350541368126869,
           0.013311188668012619,
           0.010950998403131962,
           0.0021597729064524174,
           0.0020628655329346657,
           0.013813015073537827,
           0.0022899932228028774,
           0.010555187240242958,
           0.004571127239614725,
           0.009076389484107494,
           0.012745130807161331,
           0.031193716451525688,
           0.012818265706300735,
           0.007474105805158615,
           0.017473526298999786,
           0.10250852257013321,
           0.010584353469312191,
           0.04306585714221001,
           0.0391756035387516,
           0.023313920944929123,
           0.04296235367655754,
           0.0054314639419317245,
           0.012482672929763794,
           0.019835323095321655,
           0.013311020098626614,
           0.010945144109427929,
           0.005943142343312502,
           0.013673663139343262,
           0.008265871554613113,
           0.010834473185241222,
           0.005332615692168474,
           0.02123713493347168,
           0.020234864205121994,
           0.002631973009556532,
           0.0036299186758697033,
           0.011564237996935844,
           0.006709401961416006,
           0.030846312642097473,
           0.003935499116778374,
           0.0018188628600910306,
           0.027260420843958855,
           0.016916092485189438,
           0.019000504165887833,
           0.006124309729784727,
           0.04690646007657051,
           0.012115123681724072,
           0.0073499009013175964,
           0.004404853098094463,
           0.005150366574525833,
           0.041404109448194504,
           0.008319146931171417,
           0.007814873941242695,
           0.028401769697666168,
           0.005094038788229227,
           0.032361309975385666,
           0.003964622505009174,
           0.004617335740476847
          ],
          [
           0.006379541475325823,
           0.005444021429866552,
           0.0017667069332674146,
           0.011056155897676945,
           0.003975079860538244,
           0.0063863396644592285,
           0.009031262248754501,
           0.06411563605070114,
           0.017190050333738327,
           0.008136307820677757,
           0.0006782190757803619,
           0.0014993163058534265,
           0.012927722185850143,
           0.0007301185396499932,
           0.028364086523652077,
           0.0012619300978258252,
           0.004816815257072449,
           0.011756319552659988,
           0.015716753900051117,
           0.013445542193949223,
           0.058948252350091934,
           0.06509508192539215,
           0.025783756747841835,
           0.0024487220216542482,
           0.019440744072198868,
           0.048440419137477875,
           0.022236648947000504,
           0.04742062836885452,
           0.004077669233083725,
           0.009750126861035824,
           0.014423474669456482,
           0.007275921292603016,
           0.015750469639897346,
           0.005997525528073311,
           0.016080524772405624,
           0.008935053832828999,
           0.0039413427002727985,
           0.023519670590758324,
           0.02241981215775013,
           0.024176843464374542,
           0.005700542591512203,
           0.004548581782728434,
           0.02380909025669098,
           0.0035737205762416124,
           0.01308111660182476,
           0.003780258819460869,
           0.00040152866858989,
           0.002558628562837839,
           0.01319215539842844,
           0.019381927326321602,
           0.007840125821530819,
           0.060414452105760574,
           0.010681039653718472,
           0.011037847027182579,
           0.000801926595158875,
           0.07573296129703522,
           0.0045123230665922165,
           0.0036579647567123175,
           0.0017900492530316114,
           0.03904793784022331,
           0.00153913046233356,
           0.008840455673635006,
           0.0011957139940932393,
           0.0120398486033082
          ],
          [
           0.01498626172542572,
           0.008223457261919975,
           0.07221397757530212,
           0.014694630168378353,
           0.011963142082095146,
           0.017530962824821472,
           0.008053531870245934,
           0.0015121300239115953,
           0.017670560628175735,
           0.015804016962647438,
           0.0035318820737302303,
           0.01535387896001339,
           0.01646982692182064,
           0.004370103124529123,
           0.0039079394191503525,
           0.03599292039871216,
           0.026572270318865776,
           0.01798688992857933,
           0.02046533115208149,
           0.016816865652799606,
           0.007817625068128109,
           0.001050102524459362,
           0.04608641192317009,
           0.033406827598810196,
           0.03333740681409836,
           0.017062801867723465,
           0.005305842496454716,
           0.009807376191020012,
           0.0114182960242033,
           0.014233998022973537,
           0.016662849113345146,
           0.012448803521692753,
           0.009067348204553127,
           0.01561572402715683,
           0.020207691937685013,
           0.015124303288757801,
           0.01940503716468811,
           0.011801294982433319,
           0.007432803511619568,
           0.006923989858478308,
           0.0161554254591465,
           0.01335933618247509,
           0.03127240389585495,
           0.017975451424717903,
           0.014047943986952305,
           0.006344204302877188,
           0.0023355884477496147,
           0.03437454625964165,
           0.013202501460909843,
           0.004329039715230465,
           0.008015039376914501,
           0.023457229137420654,
           0.011355417780578136,
           0.022476164624094963,
           0.0500272773206234,
           0.0009731349418871105,
           0.00116217031609267,
           0.02188114821910858,
           0.005081733223050833,
           0.019822368398308754,
           0.0030112839303910732,
           0.0008988691261038184,
           0.018292218446731567,
           0.0018124114722013474
          ],
          [
           0.004471885040402412,
           0.0063569252379238605,
           0.0011057626688852906,
           0.014619014225900173,
           0.08371239900588989,
           0.0027942475862801075,
           0.008499016053974628,
           0.05688846483826637,
           0.008416008204221725,
           0.008913824334740639,
           0.015521381981670856,
           0.008392791263759136,
           0.01079467311501503,
           0.01460699550807476,
           0.011229700408875942,
           0.002415518509224057,
           0.0169504564255476,
           0.008512599393725395,
           0.022585976868867874,
           0.004896552301943302,
           0.008857550099492073,
           0.035530935972929,
           0.009627159684896469,
           0.001551064313389361,
           0.0186967421323061,
           0.06334715336561203,
           0.017591549083590508,
           0.03745020925998688,
           0.013400256633758545,
           0.015376636758446693,
           0.010156434960663319,
           0.005717315711081028,
           0.012818590737879276,
           0.004389765672385693,
           0.015665845945477486,
           0.008399326354265213,
           0.003350790124386549,
           0.01617060974240303,
           0.014390021562576294,
           0.008412427268922329,
           0.0026948051527142525,
           0.002103871200233698,
           0.01828879304230213,
           0.0025453874841332436,
           0.003394481958821416,
           0.002697533927857876,
           0.013199621811509132,
           0.003920102491974831,
           0.027108538895845413,
           0.036463093012571335,
           0.007250120863318443,
           0.06144523248076439,
           0.010675439611077309,
           0.005524085834622383,
           0.0015581224579364061,
           0.011229980736970901,
           0.07183195650577545,
           0.006157322786748409,
           0.003309820778667927,
           0.022996937856078148,
           0.004909667186439037,
           0.03909474238753319,
           0.0024841695558279753,
           0.006531619932502508
          ],
          [
           0.003899847622960806,
           0.0050751990638673306,
           0.0013498460175469518,
           0.019603552296757698,
           0.004027952440083027,
           0.003952644299715757,
           0.0071730404160916805,
           0.07282311469316483,
           0.00914756115525961,
           0.005275710020214319,
           0.0011254651471972466,
           0.0014947947347536683,
           0.007721997331827879,
           0.0011682211188599467,
           0.016391944140195847,
           0.0014376739272847772,
           0.0063208239153027534,
           0.01202439796179533,
           0.01724967733025551,
           0.008172872476279736,
           0.034684158861637115,
           0.07356832921504974,
           0.013428564183413982,
           0.0019509147386997938,
           0.01294162031263113,
           0.06602472811937332,
           0.01992599293589592,
           0.04047079011797905,
           0.004547575023025274,
           0.013194883242249489,
           0.010897457599639893,
           0.004095593933016062,
           0.0171425212174654,
           0.006616894621402025,
           0.02054133452475071,
           0.006758613511919975,
           0.002609026851132512,
           0.019453125074505806,
           0.018363460898399353,
           0.011990475468337536,
           0.01058958563953638,
           0.004961037542670965,
           0.04686371982097626,
           0.0016746511682868004,
           0.007429238874465227,
           0.0029537708032876253,
           0.0007383726187981665,
           0.0020191341172903776,
           0.02066165767610073,
           0.041875023394823074,
           0.005118774715811014,
           0.07683544605970383,
           0.014960127882659435,
           0.008266700431704521,
           0.0012951090466231108,
           0.08191987127065659,
           0.007005823310464621,
           0.0033203549683094025,
           0.0021424079313874245,
           0.03073379397392273,
           0.004072160460054874,
           0.009539434686303139,
           0.0013809484662488103,
           0.009000364691019058
          ],
          [
           0.012507450766861439,
           0.0068801152519881725,
           0.07055551558732986,
           0.015518052503466606,
           0.01505478098988533,
           0.018022440373897552,
           0.012780222110450268,
           0.0014616103144362569,
           0.015920286998152733,
           0.014840459451079369,
           0.005318962503224611,
           0.012735176831483841,
           0.017987757921218872,
           0.00611787149682641,
           0.0036711296997964382,
           0.03903889283537865,
           0.03786206990480423,
           0.015576299279928207,
           0.020003780722618103,
           0.01527897734194994,
           0.005592857953161001,
           0.001085248775780201,
           0.017008526250720024,
           0.02035466395318508,
           0.025167733430862427,
           0.01805698126554489,
           0.0037474145647138357,
           0.009373344480991364,
           0.013937701471149921,
           0.015046379528939724,
           0.016371212899684906,
           0.010183277539908886,
           0.018419569358229637,
           0.02123395912349224,
           0.017516734078526497,
           0.02398686483502388,
           0.011778085492551327,
           0.01611172966659069,
           0.006389584857970476,
           0.006609668489545584,
           0.0319470539689064,
           0.011225876398384571,
           0.025714969262480736,
           0.01680188812315464,
           0.010583784431219101,
           0.0059190853498876095,
           0.0038754164706915617,
           0.048571400344371796,
           0.012998240068554878,
           0.0038483981043100357,
           0.007686085067689419,
           0.038591619580984116,
           0.009599290788173676,
           0.021917937323451042,
           0.03647803142666817,
           0.0010823217453435063,
           0.0017998235998675227,
           0.023228947073221207,
           0.004955579526722431,
           0.014224421232938766,
           0.0032859514467418194,
           0.0012388062896206975,
           0.02818700484931469,
           0.0011346820974722505
          ],
          [
           0.012107406742870808,
           0.01713886484503746,
           0.0020607446786016226,
           0.03451750427484512,
           0.04359859973192215,
           0.01722121238708496,
           0.013411381281912327,
           0.0020492097828537226,
           0.017727546393871307,
           0.01863180287182331,
           0.008671441115438938,
           0.01353408582508564,
           0.04907600209116936,
           0.00628573726862669,
           0.005356768146157265,
           0.0016404950292780995,
           0.009778918698430061,
           0.0213715061545372,
           0.012557826936244965,
           0.012144695967435837,
           0.002447600942105055,
           0.0016032825224101543,
           0.01155906356871128,
           0.003981677815318108,
           0.041332148015499115,
           0.034651029855012894,
           0.011260824277997017,
           0.011844761669635773,
           0.007532385643571615,
           0.019052639603614807,
           0.01687704212963581,
           0.007838134653866291,
           0.009621035307645798,
           0.01505256723612547,
           0.017322219908237457,
           0.012093744240701199,
           0.017398783937096596,
           0.009409544989466667,
           0.009635460563004017,
           0.00790244061499834,
           0.009555713273584843,
           0.010803261771798134,
           0.012625165283679962,
           0.012799512594938278,
           0.016283681616187096,
           0.001669483375735581,
           0.010767623782157898,
           0.005544462241232395,
           0.004622470121830702,
           0.01083510834723711,
           0.005140531808137894,
           0.040479183197021484,
           0.09530708938837051,
           0.009981400333344936,
           0.001007371349260211,
           0.00115307723172009,
           0.0037158241029828787,
           0.013564304448664188,
           0.06254436075687408,
           0.01675773598253727,
           0.06065108999609947,
           0.004182045813649893,
           0.00136203330475837,
           0.0013493199367076159
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Input 1 (What's the musical pitch of that note?)",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Input 2 (How will you pitch your idea to the investors?)",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Expert vs Token Heatmaps for Two Inputs"
        },
        "width": 2000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Experts"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Tokens"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_heatmap(probabilities, tokens, title):\n",
    "    return go.Heatmap(\n",
    "        z=probabilities,\n",
    "        x=[f'Expert {i}' for i in range(probabilities.shape[1])],\n",
    "        y=tokens,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Probability'),\n",
    "        hovertemplate='Token: %{y}<br>Expert: %{x}<br>Probability: %{z:.4f}<extra></extra>'\n",
    "    )\n",
    "\n",
    "# Convert router logits to probabilities for both inputs\n",
    "probabilities_1 = F.softmax(last_layer_router_logits, dim=-1).cpu().numpy()\n",
    "probabilities_2 = F.softmax(last_layer_router_logits_2, dim=-1).cpu().numpy()\n",
    "\n",
    "# Create lists of tokens for both inputs\n",
    "tokens_1 = [tokenizer.decode([token_id]) for token_id in tokenizer.encode(input_text, return_tensors=\"pt\")[0]]\n",
    "tokens_2 = [tokenizer.decode([token_id]) for token_id in tokenizer.encode(input_text_2, return_tensors=\"pt\")[0]]\n",
    "\n",
    "# Create DataFrames for the heatmaps\n",
    "df_1 = pd.DataFrame(probabilities_1, index=tokens_1)\n",
    "df_2 = pd.DataFrame(probabilities_2, index=tokens_2)\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(f'Input 1 ({input_text})', f'Input 2 ({input_text_2})'))\n",
    "\n",
    "# Add heatmaps to subplots\n",
    "fig.add_trace(create_heatmap(probabilities_1, tokens_1, 'Input 1'), row=1, col=1)\n",
    "fig.add_trace(create_heatmap(probabilities_2, tokens_2, 'Input 2'), row=1, col=2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Expert vs Token Heatmaps for Two Inputs',\n",
    "    xaxis_title='Experts',\n",
    "    yaxis_title='Tokens',\n",
    "    width=2000,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Save the plot as an HTML file (optional)\n",
    "fig.write_html(\"expert_token_heatmaps_comparison.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
