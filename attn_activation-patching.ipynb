{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from transformers import AutoTokenizer, AutoModelForCausalLM, OlmoeConfig"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfe56447da024e7ebf19c33cf62dace5","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["OlmoeForCausalLM(\n","  (model): OlmoeModel(\n","    (embed_tokens): Embedding(50304, 2048, padding_idx=1)\n","    (layers): ModuleList(\n","      (0-15): 16 x OlmoeDecoderLayer(\n","        (self_attn): OlmoeSdpaAttention(\n","          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n","          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n","          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n","          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n","          (q_norm): OlmoeRMSNorm((2048,), eps=1e-05)\n","          (k_norm): OlmoeRMSNorm((2048,), eps=1e-05)\n","        )\n","        (mlp): OlmoeSparseMoeBlock(\n","          (gate): Linear(in_features=2048, out_features=64, bias=False)\n","          (experts): ModuleList(\n","            (0-63): 64 x OlmoeMLP(\n","              (gate_proj): Linear(in_features=2048, out_features=1024, bias=False)\n","              (up_proj): Linear(in_features=2048, out_features=1024, bias=False)\n","              (down_proj): Linear(in_features=1024, out_features=2048, bias=False)\n","              (act_fn): SiLU()\n","            )\n","          )\n","        )\n","        (input_layernorm): OlmoeRMSNorm((2048,), eps=1e-05)\n","        (post_attention_layernorm): OlmoeRMSNorm((2048,), eps=1e-05)\n","      )\n","    )\n","    (norm): OlmoeRMSNorm((2048,), eps=1e-05)\n","    (rotary_emb): OlmoeRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",")"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForCausalLM.from_pretrained(\"allenai/OLMoE-1B-7B-0924\")\n","tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMoE-1B-7B-0924\")\n","\n","# Set the model to eval mode\n","model.eval()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def get_attention_tensor(input_text, model, tokenizer, layer_num):\n","    # Tokenize the input\n","    inputs = tokenizer(input_text, return_tensors=\"pt\")\n","\n","    # Print the tokenized input\n","    print(\"Tokenized input:\")\n","    for token_id in inputs.input_ids[0]:\n","        token = tokenizer.decode([token_id])\n","        print(f\"Token: '{token}', ID: {token_id.item()}\")\n","\n","    print(f\"\\nInput shape: {inputs.input_ids.shape}\")\n","\n","    # Forward pass with output_attentions=True\n","    with torch.no_grad():\n","        outputs = model(**inputs, output_attentions=True)\n","\n","    # Get the attention tensor from the specified layer\n","    attention_tensor = outputs.attentions[layer_num]\n","    \n","    print(f\"\\nAttention tensor shape: {attention_tensor.shape}\")\n","    \n","    # format of attnetion tensor?\n","    \n","    # Print which layer the attention tensor is from\n","    print(f\"Attention tensor is from layer {layer_num} of the model\")\n","\n","    # Initialize a list to store attention weights for each token\n","    all_attention_weights = []\n","\n","    # Print attention weights for each token\n","    for token_idx, token_id in enumerate(inputs.input_ids[0]):\n","        token = tokenizer.decode([token_id])\n","        attention_weights = attention_tensor[:, :, token_idx, :].squeeze(0)\n","        \n","        # Append the attention weights to the list\n","        all_attention_weights.append(attention_weights.tolist())\n","\n","    return attention_tensor"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenized input:\n","Token: 'The', ID: 510\n","Token: ' capital', ID: 5347\n","Token: ' city', ID: 2846\n","Token: ' of', ID: 273\n","Token: ' France', ID: 6181\n","Token: ' is', ID: 310\n","\n","Input shape: torch.Size([1, 6])\n","\n","Attention tensor shape: torch.Size([1, 16, 6, 6])\n","Attention tensor is from layer 0 of the model\n","tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [5.8542e-01, 4.1458e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [4.2129e-01, 2.9937e-01, 2.7934e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.7586e-01, 2.1433e-01, 2.0015e-01, 3.0966e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [2.4056e-01, 1.6639e-01, 1.5372e-01, 2.7955e-01, 1.5978e-01,\n","           0.0000e+00],\n","          [1.8133e-01, 1.4626e-01, 1.3953e-01, 1.9880e-01, 1.4343e-01,\n","           1.9064e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [8.1084e-01, 1.8916e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [9.0715e-02, 8.0169e-01, 1.0760e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.3280e-02, 1.1959e-01, 5.3704e-01, 3.2010e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [2.2979e-04, 2.6367e-03, 1.9802e-01, 6.0229e-01, 1.9683e-01,\n","           0.0000e+00],\n","          [1.6045e-03, 1.5704e-03, 9.1610e-03, 2.3016e-01, 3.3594e-01,\n","           4.2157e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [4.9924e-01, 5.0076e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [3.3310e-01, 3.3338e-01, 3.3352e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.4994e-01, 2.5017e-01, 2.5005e-01, 2.4984e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [2.0012e-01, 1.9995e-01, 2.0008e-01, 1.9983e-01, 2.0001e-01,\n","           0.0000e+00],\n","          [1.6678e-01, 1.6679e-01, 1.6647e-01, 1.6669e-01, 1.6648e-01,\n","           1.6680e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [4.7842e-01, 5.2158e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [3.2825e-01, 3.2484e-01, 3.4690e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.3135e-01, 2.1440e-01, 2.5227e-01, 3.0198e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [1.9142e-01, 2.0263e-01, 2.0126e-01, 2.0332e-01, 2.0138e-01,\n","           0.0000e+00],\n","          [1.6055e-01, 1.4182e-01, 1.6845e-01, 1.9909e-01, 1.4499e-01,\n","           1.8509e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [9.9995e-01, 4.8428e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [9.9981e-01, 8.6343e-05, 1.0528e-04, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.0068e-03, 3.3740e-01, 5.7669e-01, 8.3900e-02, 0.0000e+00,\n","           0.0000e+00],\n","          [9.9514e-01, 6.8944e-05, 6.9266e-05, 4.6237e-03, 1.0006e-04,\n","           0.0000e+00],\n","          [1.2435e-03, 2.6818e-01, 3.9029e-01, 3.9909e-02, 2.5774e-01,\n","           4.2638e-02]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [8.3764e-01, 1.6236e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [6.2994e-01, 2.9551e-01, 7.4552e-02, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [4.0354e-01, 2.7827e-01, 1.7085e-01, 1.4734e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [2.1598e-01, 2.3865e-01, 3.4534e-01, 1.2086e-01, 7.9174e-02,\n","           0.0000e+00],\n","          [1.9212e-01, 1.0303e-01, 1.5012e-01, 2.6547e-01, 1.7602e-01,\n","           1.1323e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [7.3506e-01, 2.6495e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [5.9331e-01, 2.0555e-01, 2.0115e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [3.7994e-01, 1.0495e-01, 1.1883e-01, 3.9628e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [3.3253e-01, 1.3598e-01, 1.2459e-01, 2.2895e-01, 1.7796e-01,\n","           0.0000e+00],\n","          [1.9304e-01, 5.3031e-02, 5.7659e-02, 1.7870e-01, 6.9398e-02,\n","           4.4818e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [4.5495e-01, 5.4505e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.9121e-01, 3.5015e-01, 3.5864e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.3611e-01, 2.6979e-01, 2.7451e-01, 2.1958e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [1.7678e-01, 2.1972e-01, 2.2602e-01, 1.5704e-01, 2.2045e-01,\n","           0.0000e+00],\n","          [1.5574e-01, 1.8354e-01, 1.8750e-01, 1.4243e-01, 1.8400e-01,\n","           1.4679e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [5.0073e-01, 4.9927e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [3.3362e-01, 3.3303e-01, 3.3335e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.5454e-01, 2.5865e-01, 2.6061e-01, 2.2620e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [1.9940e-01, 1.9968e-01, 1.9991e-01, 2.0068e-01, 2.0032e-01,\n","           0.0000e+00],\n","          [1.7075e-01, 1.7074e-01, 1.7097e-01, 1.5776e-01, 1.6236e-01,\n","           1.6742e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [5.3894e-01, 4.6106e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [3.7040e-01, 3.1806e-01, 3.1154e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.7019e-01, 2.2221e-01, 2.1720e-01, 2.9040e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [2.1977e-01, 1.8661e-01, 1.8216e-01, 2.3166e-01, 1.7980e-01,\n","           0.0000e+00],\n","          [1.8270e-01, 1.4989e-01, 1.4590e-01, 1.9828e-01, 1.4198e-01,\n","           1.8126e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [3.4236e-01, 6.5764e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.4641e-01, 3.6831e-01, 3.8529e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.4994e-01, 2.5350e-01, 2.6185e-01, 2.3471e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [1.5002e-01, 2.1725e-01, 2.4131e-01, 1.2992e-01, 2.6151e-01,\n","           0.0000e+00],\n","          [1.7473e-01, 1.6243e-01, 1.6815e-01, 1.5939e-01, 1.8008e-01,\n","           1.5522e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.3901e-01, 7.6099e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.5100e-01, 3.3345e-01, 4.1555e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [1.6223e-01, 1.1174e-01, 7.7908e-02, 6.4812e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [1.7288e-01, 2.0403e-01, 3.0248e-01, 7.1839e-02, 2.4877e-01,\n","           0.0000e+00],\n","          [2.7608e-01, 8.1162e-02, 8.4925e-02, 2.3276e-01, 8.9927e-02,\n","           2.3515e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [5.0125e-01, 4.9875e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [3.3301e-01, 3.3387e-01, 3.3311e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.4971e-01, 2.5012e-01, 2.5009e-01, 2.5008e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [1.9632e-01, 2.0121e-01, 2.0069e-01, 2.0060e-01, 2.0118e-01,\n","           0.0000e+00],\n","          [1.6661e-01, 1.6661e-01, 1.6672e-01, 1.6675e-01, 1.6660e-01,\n","           1.6671e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [4.9988e-01, 5.0012e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [3.3222e-01, 3.3278e-01, 3.3499e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [2.5076e-01, 2.5082e-01, 2.4870e-01, 2.4972e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [1.9862e-01, 1.9830e-01, 2.0159e-01, 2.0002e-01, 2.0147e-01,\n","           0.0000e+00],\n","          [1.6791e-01, 1.6803e-01, 1.6566e-01, 1.6679e-01, 1.6536e-01,\n","           1.6625e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [5.9546e-03, 9.9405e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [8.3674e-03, 1.1849e-01, 8.7314e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [1.8931e-02, 4.2825e-03, 2.9594e-02, 9.4719e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [6.7917e-04, 2.0327e-04, 2.0545e-03, 4.4035e-03, 9.9266e-01,\n","           0.0000e+00],\n","          [1.2769e-01, 2.8930e-03, 3.5473e-03, 4.7787e-02, 1.3117e-02,\n","           8.0497e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [5.4836e-03, 9.9452e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [6.3389e-04, 5.7565e-02, 9.4180e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00],\n","          [1.8581e-04, 9.8660e-04, 3.0858e-02, 9.6797e-01, 0.0000e+00,\n","           0.0000e+00],\n","          [3.7838e-08, 1.3976e-08, 1.7319e-05, 3.1443e-03, 9.9684e-01,\n","           0.0000e+00],\n","          [1.8695e-04, 2.7203e-05, 7.8532e-05, 4.1420e-03, 2.8585e-02,\n","           9.6698e-01]]]])\n"]}],"source":["# for testing this function\n","input_text = \"The capital city of France is\"\n","layer_num = 0\n","\n","x =  get_attention_tensor(input_text, model, tokenizer, layer_num)\n","print(x)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenized input:\n","Token: 'The', ID: 510\n","Token: ' capital', ID: 5347\n","Token: ' city', ID: 2846\n","Token: ' of', ID: 273\n","Token: ' India', ID: 5427\n","Token: ' United', ID: 1986\n","Token: ' States', ID: 2077\n","Token: ' is', ID: 310\n","\n","Input shape: torch.Size([1, 8])\n","\n","Attention tensor shape: torch.Size([1, 16, 8, 8])\n","Attention tensor is from layer 0 of the model\n","tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [5.8542e-01, 4.1458e-01, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [4.2129e-01, 2.9937e-01, 2.7934e-01,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          ...,\n","          [2.1696e-01, 1.3829e-01, 1.2574e-01,  ..., 1.2326e-01,\n","           0.0000e+00, 0.0000e+00],\n","          [1.7966e-01, 1.2470e-01, 1.1679e-01,  ..., 1.1387e-01,\n","           1.3353e-01, 0.0000e+00],\n","          [1.4032e-01, 1.1320e-01, 1.0813e-01,  ..., 1.0715e-01,\n","           1.1795e-01, 1.4754e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [8.1084e-01, 1.8916e-01, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [9.0714e-02, 8.0169e-01, 1.0760e-01,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          ...,\n","          [2.8717e-05, 2.3057e-05, 1.2363e-03,  ..., 8.3757e-02,\n","           0.0000e+00, 0.0000e+00],\n","          [6.7963e-04, 1.0475e-04, 3.3988e-04,  ..., 6.2828e-01,\n","           1.3322e-01, 0.0000e+00],\n","          [4.6379e-03, 1.9896e-03, 1.3247e-03,  ..., 1.2718e-01,\n","           3.6320e-01, 4.8151e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [4.9924e-01, 5.0076e-01, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [3.3310e-01, 3.3338e-01, 3.3352e-01,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          ...,\n","          [1.6665e-01, 1.6662e-01, 1.6688e-01,  ..., 1.6644e-01,\n","           0.0000e+00, 0.0000e+00],\n","          [1.4274e-01, 1.4283e-01, 1.4308e-01,  ..., 1.4260e-01,\n","           1.4289e-01, 0.0000e+00],\n","          [1.2510e-01, 1.2495e-01, 1.2490e-01,  ..., 1.2517e-01,\n","           1.2483e-01, 1.2506e-01]],\n","\n","         ...,\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [4.9988e-01, 5.0012e-01, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [3.3222e-01, 3.3278e-01, 3.3499e-01,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          ...,\n","          [1.6677e-01, 1.6717e-01, 1.6605e-01,  ..., 1.6666e-01,\n","           0.0000e+00, 0.0000e+00],\n","          [1.4380e-01, 1.4388e-01, 1.4099e-01,  ..., 1.4354e-01,\n","           1.4305e-01, 0.0000e+00],\n","          [1.2564e-01, 1.2572e-01, 1.2395e-01,  ..., 1.2548e-01,\n","           1.2521e-01, 1.2439e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [5.9546e-03, 9.9405e-01, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [8.3674e-03, 1.1849e-01, 8.7314e-01,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          ...,\n","          [2.5177e-03, 1.0048e-03, 1.3720e-03,  ..., 8.3488e-01,\n","           0.0000e+00, 0.0000e+00],\n","          [1.2188e-02, 3.3849e-03, 1.5066e-03,  ..., 1.4422e-01,\n","           8.2040e-01, 0.0000e+00],\n","          [1.6895e-01, 4.9313e-03, 1.2061e-02,  ..., 5.2415e-03,\n","           2.0575e-02, 7.5769e-01]],\n","\n","         [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [5.4836e-03, 9.9452e-01, 0.0000e+00,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          [6.3389e-04, 5.7565e-02, 9.4180e-01,  ..., 0.0000e+00,\n","           0.0000e+00, 0.0000e+00],\n","          ...,\n","          [1.9539e-07, 7.4523e-09, 6.2862e-08,  ..., 9.4769e-01,\n","           0.0000e+00, 0.0000e+00],\n","          [5.4119e-05, 3.0034e-06, 8.4569e-07,  ..., 5.2910e-02,\n","           9.4645e-01, 0.0000e+00],\n","          [8.0623e-03, 4.7425e-04, 6.2216e-05,  ..., 1.1810e-03,\n","           5.7754e-02, 9.3237e-01]]]])\n"]}],"source":["# for testing this function\n","input_text = \"The capital city of India United States is\"\n","layer_num = 0\n","\n","x =  get_attention_tensor(input_text, model, tokenizer, layer_num)\n","print(x)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def patch_attention(model, tokenizer, input_1: str, input_2: str, max_new_tokens: int = 20):\n","    \"\"\"\n","    Run attention patching experiment with pre-initialized model.\n","    \"\"\"\n","    device = next(model.parameters()).device\n","    \n","    print(f\"\\nAttention Implementation: {model.config._attn_implementation}\")\n","    \n","    tokens_1 = tokenizer(input_1, return_tensors=\"pt\").to(device)\n","    tokens_2 = tokenizer(input_2, return_tensors=\"pt\").to(device)\n","    \n","    print(f\"\\nInput 1 sequence length: {tokens_1['input_ids'].shape[1]}\")\n","    print(f\"Input 2 sequence length: {tokens_2['input_ids'].shape[1]}\")\n","\n","    stored_outputs = []\n","    \n","    def store_attention(module, input, output):\n","        stored_outputs.append(output)  # Store complete output tuple\n","        if len(stored_outputs) == 1:\n","            if isinstance(output, tuple):\n","                print(f\"\\nOutput is a tuple with {len(output)} elements\")\n","                for i, o in enumerate(output):\n","                    if isinstance(o, torch.Tensor):\n","                        print(f\"Output[{i}] shape: {o.shape}\")\n","            else:\n","                print(f\"\\nOutput shape: {output.shape}\")\n","        return output\n","    \n","    print(\"\\nRegistering storage hooks...\")\n","    hooks = []\n","    for i, layer in enumerate(model.model.layers):\n","        hooks.append(layer.self_attn.register_forward_hook(store_attention))\n","\n","    print(f\"\\nGenerating with input_1: '{input_1}'\")\n","    with torch.no_grad():\n","        output_1 = model.generate(\n","            **tokens_1,\n","            max_new_tokens=max_new_tokens,\n","            pad_token_id=tokenizer.pad_token_id\n","        )\n","    \n","    print(f\"\\nStored attention outputs from {len(stored_outputs)} layers\")\n","    \n","    for hook in hooks:\n","        hook.remove()\n","    \n","    print(f\"\\nGenerating with input_2: '{input_2}'\")\n","    with torch.no_grad():\n","        output_2 = model.generate(\n","            **tokens_2,\n","            max_new_tokens=max_new_tokens,\n","            pad_token_id=tokenizer.pad_token_id\n","        )\n","    \n","    print(\"\\nRegistering patching hooks...\")\n","    hooks = []\n","    \n","    def patch_attention(layer_idx):\n","        def hook(module, input, output):\n","            # if layer_idx == 0:\n","            #     print(f\"\\nLayer {layer_idx} patching:\")\n","            #     if isinstance(output, tuple):\n","            #         print(f\"Output is a tuple with {len(output)} elements\")\n","            #         for i, o in enumerate(output):\n","            #             if isinstance(o, torch.Tensor):\n","            #                 print(f\"Output[{i}] shape: {o.shape}\")\n","            return stored_outputs[layer_idx]  # Return complete stored output tuple\n","        return hook\n","    \n","    for i, layer in enumerate(model.model.layers):\n","        hooks.append(layer.self_attn.register_forward_hook(patch_attention(i)))\n","\n","    print(f\"\\nGenerating with patched attention...\")\n","    with torch.no_grad():\n","        output_patched = model.generate(\n","            **tokens_2,\n","            max_new_tokens=max_new_tokens,\n","            pad_token_id=tokenizer.pad_token_id\n","        )\n","\n","    for hook in hooks:\n","        hook.remove()\n","\n","    output_1_text = tokenizer.decode(output_1[0], skip_special_tokens=True)\n","    output_2_text = tokenizer.decode(output_2[0], skip_special_tokens=True)\n","    output_patched_text = tokenizer.decode(output_patched[0], skip_special_tokens=True)\n","\n","    print(\"\\nFinal Outputs:\")\n","    print(f\"Input 1 ({input_1}) Output: {output_1_text}\")\n","    print(f\"Input 2 ({input_2}) Output: {output_2_text}\")\n","    print(f\"Patched Output: {output_patched_text}\")\n","\n","    return output_1_text, output_2_text, output_patched_text"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Attention Implementation: sdpa\n","\n","Input 1 sequence length: 6\n","Input 2 sequence length: 6\n","\n","Registering storage hooks...\n","\n","Generating with input_1: 'The capital city of France is'\n","\n","Output is a tuple with 3 elements\n","Output[0] shape: torch.Size([1, 6, 2048])\n","\n","Stored attention outputs from 320 layers\n","\n","Generating with input_2: 'The capital city of India is'\n","\n","Registering patching hooks...\n","\n","Generating with patched attention...\n","\n","Final Outputs:\n","Input 1 (The capital city of France is) Output: The capital city of France is Paris.\n","\n","The capital city of Germany is Berlin.\n","\n","The capital city of Italy is\n","Input 2 (The capital city of India is) Output: The capital city of India is New Delhi.\n","\n","The capital city of India is New Delhi.\n","\n","The capital city of\n","Patched Output: The capital city of India is Paris, Paris, Paris, Paris, Paris, Paris, Paris, Paris, Paris, Paris,\n"]}],"source":["output_1, output_2, output_patched = patch_attention(\n","    model,\n","    tokenizer, \n","    \"The capital city of France is\",\n","    \"The capital city of India is\"\n",")"]}],"metadata":{"kernelspec":{"display_name":"ai_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
